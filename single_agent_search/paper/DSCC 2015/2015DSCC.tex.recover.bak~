%%%%%%%%%%%%%%%%%%%%%%%%%%% asme2e.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template for producing ASME-format articles using LaTeX            %
% Written by   Harry H. Cheng                                        %
%              Integration Engineering Laboratory                    %
%              Department of Mechanical and Aeronautical Engineering %
%              University of California                              %
%              Davis, CA 95616                                       %
%              Tel: (530) 752-5020 (office)                          %
%                   (530) 752-1028 (lab)                             %
%              Fax: (530) 752-4158                                   %
%              Email: hhcheng@ucdavis.edu                            %
%              WWW:   http://iel.ucdavis.edu/people/cheng.html       %
%              May 7, 1994                                           %
% Modified: February 16, 2001 by Harry H. Cheng                      %
% Modified: January  01, 2003 by Geoffrey R. Shiflett                %
% Use at your own risk, send complaints to /dev/null                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% use twocolumn and 10pt options with the asme2e format
\documentclass[twocolumn,10pt]{asme2e}
\special{papersize=8.5in,11in}

%% The class has several options
%  onecolumn/twocolumn - format for one or two columns per page
%  10pt/11pt/12pt - use 10, 11, or 12 point font
%  oneside/twoside - format for oneside/twosided printing
%  final/draft - format for final/draft copy
%  cleanfoot - take out copyright info in footer leave page number
%  cleanhead - take out the conference banner on the title page
%  titlepage/notitlepage - put in titlepage or leave out titlepage
%  
%% The default is oneside, onecolumn, 10pt, final
\usepackage{amsmath,amssymb,amsfonts}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{coro}{Corollary}
\newtheorem{conj}{Conjecture}
\newtheorem{definition}{Definition}

%=====todonotes===== %
\usepackage{todonotes}
\usepackage{soul}
\definecolor{smoothgreen}{rgb}{0.7,1,0.7}
\sethlcolor{smoothgreen}

\newcommand{\todopara}[1]{\vspace{0px} %
\todo[inline, color=black!10]{\textbf{[Paragraph:]} {#1}} %
}
\newcommand{\todonote}[1]{\vspace{0px} %
\todo[inline, color=green!30]{\textbf{[Note:]} {#1}} %
}
\newcommand{\todoQ}[1]{\vspace{0px} %
\todo[inline, color=orange!50]{\textbf{[Note:]} {#1}} %
}
\newcommand{\todohere}[1]{\hl{(\textbf{TODO:} #1)}}

\newcommand{\hidetodos}{
\renewcommand{\todopara}[1]{}
\renewcommand{\todonote}[1]{}
\renewcommand{\todoQ}[1]{}
\renewcommand{\todohere}[1]{}}

%\hidetodos

\usepackage{graphicx}
\usepackage{subfigure}

% draw diagonal line in table
%\usepackage{slashbox}

\usepackage[hidelinks,pdftex,pdfauthor={Chang Liu, Shih-Yuan Liu, Elena L. Carano, J. Karl Hedrick},pdftitle={A framework for autonomous vehicles with goal inference and task allocation capabilities to support peer collaboration with human agents}]{hyperref}


\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage[capitalize]{cleveref}
\crefname{equation}{Eqn.}{Eqn.}
\Crefname{equation}{Equation}{Equations}


%=====Better Spacing==== %
\usepackage{microtype}
%===Discourage hyphenation===
\hyphenpenalty=1000
%\tolerance = 1000


%%% Replace here with information related to your conference
\confshortname{DSCC2015}
\conffullname{the ASME 2014 Dynamic Systems and Control Conference}

%%%%% for date in a single month, use
%\confdate{24-28}
%\confmonth{September}
%%%%% for date across two months, use
\confdate{October 22--24}
\confyear{2014}
\confcity{San Antonio, TX}
\confcountry{USA}

%%% Replace DETC2009/MESA-12345 with the number supplied to you 
%%% by ASME for your paper.
\papernum{DSCC2014-6262}

%%% You need to remove 'DRAFT: ' in the title for the final submitted version.
\title{Model predictive control-based autonomous search 

%%% first author
\author{Chang Liu\thanks{Address all correspondence to this author.}
    \affiliation{
    Vehicle Dynamics \& Control Lab\\
	Department of Mechanical Engineering\\
	University of California, Berkeley\\
	Berkeley, CA 94709\\
    Email: changliu@berkeley.edu
    }	
}

%%% second author
%%% remove the following entry for single author papers
%%% add more entries for additional authors
\author{J. Karl Hedrick
	\affiliation{
	Vehicle Dynamics \& Control Lab\\
	Department of Mechanical Engineering\\
	University of California, Berkeley\\
	Berkeley, California, 94709\\
    Email: khedrick@berkeley.edu
    }
}


\begin{document}

\maketitle

\begin{abstract}

\end{abstract}


\section*{INTRODUCTION} \label{sec:intro}

\begin{figure}
\centering
\includegraphics[width=0.35\textwidth]{figures/field_3}
\caption{ILLUSTRATION OF FIELD OF INTEREST}\label{fig:field}
\end{figure}


\section*{PROBLEM FORMULATION}\label{sec:formulation}
We consider a planar field $\mathcal{S}$ containing one static target. 
The accurate target location is unknown beforehand, though prior information about the location may be available.
An autonomous robot is taksed with localizing the target in minimum time.
There are obstacles and pedestrians in this environment, which the robot should avoid colliding with during its search process.
The robot is equipped with a binary sensor, which has two tpyes of ovservation results $\mathcal{D}$ and $\mathcal{\bar{D}}$.
$\mathcal{D}$ denotes that a target is observed by the sensor and $\mathcal{\bar{D}}$ represents that no target is observed.
To encode the information about the target position, a probability map is adopted.
A \textit{probability map} is a probability density function $f(x)$ associated with the field $\mathcal{S}$ so that the probability that the target exists in an area $\Delta$ equals
\begin{equation}
P(x\in \Delta) = \int_{\Delta} f(x)\,\mathrm{d}x
\end{equation}
and
\begin{equation}
\int_{\mathcal{S}} f(x)\,\mathrm{d}x = 1
\end{equation}
The probability map is updated as the robot sensor observes the environment in real time.
Based on the updated probability map, the robot plans a collision-free path to search for the target.

To avoid colliding with pedestrians, the robot predicts the pedestrian trajectories.
Here we use a very simple pedestrian model that a human moves in constant speed and direction. 
For more accurate prediction, readers can refer to .

\section*{Methods}
%\begin{figure}
%\centering
%\includegraphics[width=0.34\textwidth]{figures/flow_chart_uv3_modified}
%\caption{PROPOSED FRAMEWORK STRUCTURE}\label{fig:flow_chart}
%\end{figure}

\subsection*{Sensor Model}\label{subsec:sensor_model}
A sensor model is used to update the probability map based on the robot sensor's observation result.
A probabilistic sensor model is adopted in this work, which is defined as follows:
\begin{equation}
P(z=\mathcal{D}|x^t,x^s;\Sigma_s) = k\mathcal{N}(x^s,\Sigma_s)
\end{equation}
where $z$ represents the observation result, $x^t,x^s$ denote the positions of the target and the robot sensor, respectively. $\Sigma_s$ is a positive semidefinite covariance matrix for the Gaussian distribution. $k$ represents the scaling factor.
We should note that the sensor model need not to be a probability density function that integrates to $1$.
Instead, it works as a likelihood function that the value is between $0$ and $1$.
Correspondingly,
\begin{equation}
P(z=\mathcal{\bar{D}}|x^t,x^s;\Sigma_s) = 1-k\mathcal{N}(x^s,\Sigma_s)
\end{equation}
\textbf{figure} shows the probability of two observation results.
Here we assume a homogeneous sensor that the eigenvalues of $\Sigma_s$ are equal for the purpose of simplicity.
However, the method we present next also applies to a heterogeneous sensor.

\sbusection*{Updating the Probability Map}
In this section, we derive the update law of the probability map using the standard Bayesian inference framework.
Two illustrate the key concepts of the derivation, we use $f_k(x)$ to represent the probability map at time $k$ and it actually represents a conditional probability of the target position given the observation results up to time $k$:
\begin{equation}
f_k(x)=P(x^t|z_{1:k},x^s_{1:k})
\end{equation}
where $x^s_{1:k}$ are the robot sensor's positions at time $1,\dots,k$ and $z_{1:k}$ are the corresponding observation results.
The following formulas give the update law of $P(x^t|z_{1:k},x^s_{1:k}),\, k=1,\dots$
\begin{subequations}\label{eq:inference}
\begin{align}
P(x^t|z_{1:k+1},x^s_{1:k+1})& = mP(z_{k+1}|x^t,x^s_{k+1})P(x^t|z_{1:k},x^s_{1:k})
\end{equation}

\begin{subequations}\label{eq:inference}
	\begin{align}
	\end{align}
\end{subequations}
\begin{equation}\label{eqn:move_model}
P(s_{k+1}|a_k,s_k)=
\begin{cases}
1 &  \text{if }s_k\xrightarrow{a_k} s_{k+1}\\
0 &  \text{otherwise}
\end{cases},
\end{equation}

\begin{equation}\label{eqn:Boltzman}
P(a_k|s_k,g)\propto \exp(\beta Q_{g} (s_k,a_k)).
\end{equation}

\iffalse

\fi


\subsection*{Task Allocation}\label{subsec:task_alloc}

\begin{subequations}\label{eq:MILP_ori}
\begin{align}
\min_{\mathbf{x}_{allo}} \quad &\max_{v \in \mathbb{V}}  \sum_{i,j} t^v_{i,j}x^v_{i,j}\label{MILP:obj}  \\
\text{subject to} \quad &  \mathbf{x}_{allo} \in \mathbb{X}_{feasible}\label{MILP_constr}
\end{align}
\end{subequations}

\begin{equation}
\mathbf{x}_{allo} \in \mathbb{X}_{feasible}\cap \mathbb{X}_{goal} \label{MILP_constr2}
\end{equation}

\section*{SIMULATION}\label{sec:simulation}

\subsection*{Evaluating the Inference Performance}
\begin{figure}
\centering
\includegraphics[width=0.35\textwidth]{figures/sim_field2}
\caption{SIMULATION SNAPSHOT}\label{fig:sim_field2}
\end{figure}

\subsection*{Evaluating the Team Performance}
\begin{figure}
\centering
\includegraphics[width=0.35\textwidth]{figures/sim_field}
\caption{SIMULATION SNAPSHOT}\label{fig:sim_field}
\end{figure}

\section*{RESULTS \& DISCUSSION}\label{sec:results}
\begin{figure}
\centering
\includegraphics[width=0.38\textwidth]{figures/t2_find_chg_pdf}
\caption{TIME TO DETECT THE HUMAN AGENT'S CHANGE OF GOAL UNDER DIFFERENT VALUES OF RATIONALITY INDEX ($\beta$)}\label{fig:t2_find_chg}
\end{figure}

\subsection*{Detection Time of Change of Intention}

\subsection*{Inference Settling Time}


\begin{figure}
\centering
\includegraphics[width=0.38\textwidth]{figures/t_settle_pdf2_resize}
\caption{INFERENCE SETTLING TIME UNDER DIFFERENT VALUES OF RATIONALITY INDEX ($\beta$)}\label{fig:stl_time}
\end{figure}

\subsection*{Mission Completion Time}
\begin{figure}
\centering
\includegraphics[width=0.38\textwidth]{figures/time_vs_beta_pdf_resize}
\caption{MISSION COMPLETION TIME UNDER DIFFERENT VALUES OF RATIONALITY INDEX ($\beta$)}\label{fig:t_vs_beta}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=0.38\textwidth]{figures/time_vs_noise_pdf2_resize}
\caption{MISSION COMPLETION TIME UNDER DIFFERENT HUMAN ACTION RANDOMNESS ($\alpha$)}\label{fig:t_vs_noise}
%\todohere{Don't use ``No inference''. Maybe something that says resolving the MILP at every step.}
\end{figure}


\section*{CONCLUSION}\label{sec:conclusion}

\section*{ACKNOWLEDGMENT}
%\todopara{Acknowledge the funding source. (Ask Hedrick for grant number)}
This work is part of the Embedded Humans: Provably Correct Decision Making for Networks of Humans and Unmanned Systems project, a MURI project funded by the Office of Naval Research.
The authors would like to thank Professor Tom Griffiths from the Department of Psychology at the University of California, Berkeley for his suggestion on the goal inference method. 
%\todohere{Does this sentence sound formal?}
The authors also would like to thank Romain Jacob and Jared Garvey for their helpful discussions.

\bibliographystyle{asmems4}
\bibliography{references}
\end{document}
