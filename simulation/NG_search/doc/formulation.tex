%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphicx}
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{subcaption}
\usepackage[noadjust]{cite}
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath,amssymb,amsfonts} % assumes amsmath package installed
\usepackage{algorithm,algpseudocode}
%\usepackage{booktabs}
\usepackage{dsfont}
\usepackage{gensymb} % degree symbol

% format for theorems etc.
\newtheorem{thm}{\bfseries Theorem}
\newtheorem{lem}{\bfseries Lemma}
\newtheorem{cor}{\bfseries Corollary}
\newtheorem{prop}{\bfseries Proposition}
\newtheorem{rem}{\bfseries Remark}

% format for argmin, argmax
\newcommand{\argmax}{\operatornamewithlimits{argmax}}

% format for cross-reference
\usepackage[capitalize]{cleveref}
\crefname{equation}{eq.}{eq.}
\Crefname{equation}{Eq.}{Eq.}
\crefname{thm}{theorem}{theorems}
\Crefname{thm}{Theorem}{Theorems}
\crefname{lem}{lemma}{lemmas}
\Crefname{lem}{Lemma}{Lemmas}
\crefname{cor}{corollary}{corollaries}
\Crefname{cor}{Corollary}{Corollaries}
\crefname{prop}{proposition}{propositions}
\Crefname{prop}{Proposition}{Propositions}
\crefname{rem}{remark}{remarks}
\Crefname{rem}{Remark}{Remarks}

%=====todonotes===== %
\usepackage{todonotes}
\usepackage{soul}
\definecolor{smoothgreen}{rgb}{0.7,1,0.7}
\sethlcolor{smoothgreen}

\newcommand{\todopara}[1]{\vspace{0px} %
	\todo[inline, color=black!10]{\textbf{[Paragraph:]} {#1}} %
}
\newcommand{\todonote}[1]{\vspace{0px} %
	\todo[inline, color=green!30]{\textbf{[Note:]} {#1}} %
}
\newcommand{\todoQ}[1]{\vspace{0px} %
	\todo[inline, color=orange!50]{\textbf{[Note:]} {#1}} %
}
\newcommand{\todohere}[1]{\hl{(\textbf{TODO:} #1)}}

\newcommand{\hidetodos}{
	\renewcommand{\todopara}[1]{}
	\renewcommand{\todonote}[1]{}
	\renewcommand{\todoQ}[1]{}
	\renewcommand{\todohere}[1]{}
	}


\title{\LARGE \bf
Formulation of the problem}

\author{Chang Liu}%



\begin{document}

%\hidetodos % hide all todos 

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\section{Introduction}
My work can different from Charrow's work in the following aspects:
1. Instead of fitting each particle with a GMM, I generate a GMM with much smaller component number for planning purpose.
2. In the planning, I incorporate the effects of limited FOV.
3. In the path planning, I use MPC that may incorporate uncertainties.

I should mention that, strategies that only updates GMM weights are not suitable, since the GMM here is not for mode that is fixed, but for dynamically changing states. Therefore, it is important to update the mean and covariance.
\section{PROBLEM FORMULATION}\label{sec:prob_form}

\subsection{Robot and Target Motion Model}
Unicycle motion model for the mobile robot:
\begin{equation}\label{eqn:target_motion_model}
z_{k+1}=h(z_k,u^r_k),
\end{equation}
where
	\begin{align}
%		y^R_{k+1}&=f(y^R_k,u^R_k),\\
%		\text{where}\\		
		f(z_k,u^r_k)&=z_{k}+
		\begin{bmatrix}
			\cos{\theta^r_{k}}\Delta t & 0\\
			\sin{\theta^r_{k}}\Delta t & 0\\
			\Delta t & 0\\
			0 & \Delta t
		\end{bmatrix}u^r_{k}\nonumber.
	\end{align}

Motion model of the target:
\begin{align}
x_{k+1}&=f(x_k)+w_k,\;w_t\sim \mathcal{N}(0,Q)\\
\end{align}

\subsection{Modeling Sensing Domain}
Sensor sensing domain is represented as $\mathcal{F}_k=\left\lbrace [x_{1,k},x_{2,k}]\in\mathbb{R}^2|\:\|v\|_2\leq r, \angle v\in[\theta_1,\theta_2]\right\rbrace$, where $v=[x_{1,k}-z_{1,k},x_{2,k}-z_{2,k}]$.

\subsection{Sensor Measurement Model}
Measurement model:
\begin{equation}
y_{k}=g(x_k)+v_k,\;v_k
\end{equation}
It has four modes,

if $\gamma_k=1$
\begin{equation}\label{eqn:sensor_infov}
	P(Y_k|x_k)=
	\begin{cases}
		P(y_k|x_k)\sim \mathcal{N}(g(x_k),R)\\
		P(\emptyset|x_k)=0\\	
	\end{cases}
\end{equation}

if $\gamma_k=0$
\begin{equation}\label{eqn:sensor_outfov}
P(Y_k|x_k)=
\begin{cases}
P(y_k|x_k)=0\\
P(\emptyset|x_k)=1\\	
\end{cases}
\end{equation}
where $
\gamma_{k}=\mathds{1}_{\left\lbrace x_{k}\in\mathcal{F}_{k}\right\rbrace}$.

\section{MPC-based Path Planning}\label{sec:method}
\subsection{EKF with Limited Sensing Domain}\label{subseq:KF with FOV}
\begin{subequations}\label{eqn:KF}
	\begin{align}
	\hat{x}^t_{k+1|k}&=f(\hat{x}^t_{k|k})\\
	P_{k+1|k}&=A^i_kP^i_{k|k}A^{i'}_k+Q\\
	K^i_{k+1}&=P^i_{k+1|k}C^{i'}_{k+1}(C^i_{k+1}P^{i'}_{k+1|k}C^{i'}_{k+1}+R)^{-1}\\
	\hat{x}^i_{k+1|k+1}&=\hat{x}^i_{k+1|k}+\gamma_{k+1}K^i_{k+1}(y_{k+1}-h(\hat{x}^t_{k+1|k}))\label{subeqn:upd_mean}\\
	P^i_{k+1|k+1}&=P^i_{k+1|k}-\gamma_{k+1}K^i_{k+1}C^i_{k+1}P^i_{k+1|k}\label{subeqn:upd_cov},
	\end{align}
\end{subequations}
where $A^i_k=\frac{\partial f}{\partial x}|_{x=\hat{x}^i_{k|k}}$ and $C^i_{k+1}=\frac{\partial g}{\partial x}|_{x=\hat{x}^i_{k+1|k}}$. 
The $\hat{x}^t_{k|k}$ and $P_{k|k}$ represent the estimated target position and covariance matrix.
For notational simplicity, we define $b_k=[\hat{x}^t_k,P_{k|k}]$ and let $b_{k+1}=g(b_k,u^r_k)$ represent the Kalman filter defined in \Cref{eqn:KF}.

\textcolor{gray}{In the ACC 17 paper, the $\gamma$ is approximated by
\begin{equation}\label{eqn:old_gamma}
\begin{split}
\gamma_{k}&\approx \frac{1}{1+\alpha_1\|[x_{1,k},x_{2,k}]-[z_{1,k},z_{2,k}]\|_2^2}\times\\
&\quad\frac{1}{1+\exp{\left\lbrace-\alpha_2(\cos(\theta^r_k-\tilde{\theta}_k)-\cos(\theta_0))\right\rbrace}},
\end{split}
\end{equation}
where $\tilde{\theta}_k=\angle([x_{1,k},x_{2,k}]-[z_{1,k},z_{2,k}])$ is the direction angle from the sensor position to target position; $\theta_0=\frac{\theta_2-\theta_1}{2}$ is half of the sensing angle; $\alpha_1$ and $\alpha_2$ are tunning parameters that controls the shape of the function. 
\Cref{eqn:gamma} can be interpreted as follows:
when the robot is close to the target, it is more likely that the target can be detected; besides, the closer the target direction aligns with the center direction of the sensor, the higher possibility that the target will get detected.}

However, it turns out that such approximation is quite inaccurate. So I turn to the model using pure geometric method and the sigmoid function, with the latter similar to Sachin's paper.
\begin{equation}\label{eqn:gamma}
\gamma\approx \frac{1}{\gamma_1(z,\theta)}\frac{1}{\gamma_2(z,\theta)}\frac{1}{\gamma_3(z,\theta)},
\end{equation}
where \begin{align*}
\gamma_1(z,\theta)&=1+\exp^{\alpha_1(\|x-z\|^2_2-r^2)},\\
\gamma_2(z,\theta)&=1+\exp^{\alpha_2(a^T_1x-b_1)},\\
\gamma_3(z,\theta)&=1+\exp^{\alpha_3((a^T_2x-b_2)}.
\end{align*}
Here we abuse the notation of $z$. 
In this formula, $z$ represents the $x-y$ coordinate of the sensor and $\theta$ is the direction in the global coordinate. 
$r$ is the sensor range. $a_1,a_2,b_1,b_2$ are functions of $z$ and $\theta$. 
To be specific, 
\begin{equation*}
\begin{split}
a_1=[\sin\psi_1,-\cos\psi_1],\\
a_2=[-\sin\psi_2,\cos\psi_2],\\
b_1=z_1\sin\psi_1-z_2\cos\psi_1,\\
b_2=-z_1\sin\psi_2+z_2\cos\psi_2,\\
\psi_1=\theta-\theta_0, \psi_2=\theta+\theta_0.
\end{split}
\end{equation*}

\subsection{Path Planning for Target Search and Tracking}
The MPC-based path planner with planning horizon $N$ can be formulated as:
\begin{subequations}
	\begin{align}
	\min_{u_{1:N}}\; & J(b_{1:N+1},u_{1:N})\\
	\text{s.t. }\; & z_{k+1}=f(z_k,u^r_k),\label{subeqn:rbt_dyn}\\
	& b_{k+1}=g(b_k,u^r_k),\label{subeqn:est_upd}\\
	& z_{k+1}\in\mathcal{X}, \, u^r_{k+1}\in\mathcal{U},\\
	& k=1,\dots,N,
	\end{align}\label{eqn:MPC}
\end{subequations}
The objective function is
\begin{align}
J(b_{1:N+1})&=\sum\limits_{k=1}^{N+1} H(b_k)\\ %+w_2\|x_{i+1}-z_{i+1}\|^2,
& \approx -\sum\limits_{k=1}^{N+1} \sum\limits_{i=1}^{L}w_i\log  \sum\limits_{j=1}^Lw_j\mathcal{N}(\hat{x}^i_{k|k}|\hat{x}^j_{k|k},P^j_{k|k})\label{eqn:approx_obj}.
\end{align}
The approximation is the $0$-order approximation of entropy.

\subsection{Possible linearization in the iterative planning process}
\begin{enumerate}
	\item target motion matrix A
	\item sensor measurement matrix C
	\item initial solution
	\item approximate the sensor boundary
	\item linearize robot motion model
\end{enumerate}

\subsection{estimation-planning framework}
In the estimation based on the actual measurement, use the particle filter to incorporate nonlinearity and use E-M at each step to fit a GMM. mention that we can use other advanced technologies to update GMM, but here we just use a simple one.

In the planning, use $\gamma$ to update the estimation. This makes sense since if we use pseudo-measurement to update GMM, it only reinforces/bootstrapping the current GMM, brining no new info. So it makes sense to just consider the entropy of the uncertainty.

In the MPC, I may need to include the uncertainty into the obj. It seems that the only uncertainty comes from $\gamma$ in \Cref{subeqn:upd_mean,subeqn:upd_cov}.
The idea is that, since $\gamma$ is dependent on the underlying distribution of $x^i_{k+1|k}$, we can either assume MAP for the target position or use integral to compute the expected update of \Cref{subeqn:upd_mean,subeqn:upd_cov}.

\subsection{An approximate stochastic MPC framework for dealing with GMM components}
\Cref{subeqn:upd_mean,subeqn:upd_cov} can be modified to accommodate GMM components as follows:
\begin{align}
\hat{x}^i_{k+1|k+1}&=\hat{x}^i_{k+1|k}+\sum\limits_j w_j\gamma_{k+1}(\hat{x}^j_{k+1|k})K^i_{k+1}(h(\hat{x}^j_{k+1|k})-h(\hat{x}^i_{k+1|k}))\label{subeqn:upd_mean_gmm}\\
P^i_{k+1|k+1}&=P^i_{k+1|k}-\sum\limits_j w_j\gamma_{k+1}K^i_{k+1}C^i_{k+1}P^i_{k+1|k}\label{subeqn:upd_cov_gmm},
\end{align}

\subsection{Linearizing the equality constraints}
We consider \Cref{subeqn:upd_cov} for example. \Cref{subeqn:upd_cov_gmm} Can be modified accordingly.
Consider the element-wise update of $P=\begin{bmatrix}
p^{11} & p^{12}\\p^{21} & p^{22}
\end{bmatrix}$ and define $T_{k+1}=K_{k+1}C_{k+1}$, where $T=\begin{bmatrix}
t_{11} & t_{12}\\ t_{21} & t_{22}
\end{bmatrix}.$
The update rule is:
\begin{equation}\label{eqn:elementwise-upd-P}
\begin{split}
p^{11}_{k+1|k+1}&=p^{11}_{k+1|k}-\gamma_{k+1}t_{11}p^{11}_{k+1|k}-\gamma_{k+1}t_{12}p^{21}_{k+1|k}\\
p^{12}_{k+1|k+1}&=p^{12}_{k+1|k}-\gamma_{k+1}t_{11}p^{12}_{k+1|k}-\gamma_{k+1}t_{12}p^{22}_{k+1|k}\\
p^{21}_{k+1|k+1}&=p^{21}_{k+1|k}-\gamma_{k+1}t_{21}p^{11}_{k+1|k}-\gamma_{k+1}t_{22}p^{21}_{k+1|k}\\
p^{22}_{k+1|k+1}&=p^{22}_{k+1|k}-\gamma_{k+1}t_{21}p^{12}_{k+1|k}-\gamma_{k+1}t_{22}p^{22}_{k+1|k}
\end{split}
\end{equation}
We linearize them and get the following equation:
\begin{equation*}
\begin{split}
p^{11}_{k+1|k+1}&\approx \bar{p}^{11}_{k+1|k}-\bar{\gamma}_{k+1}t_{11}\bar{p}^{11}_{k+1|k}-\bar{\gamma}_{k+1}t_{12}\bar{p}^{21}_{k+1|k}\\
&+(1-\bar{\gamma}_{k+1}t_{11})(p^{11}_{k+1|k}-\bar{p}^{11}_{k+1|k})\\
&-\bar{\gamma}_{k+1}t_{12}(p^{21}_{k+1|k}-\bar{p}^{21}_{k+1|k})\\
&-(t_{11}\bar{p}^{11}_{k+1|k}+t_{12}\bar{p}^{21}_{k+1|k})(\gamma_{k+1}-\bar{\gamma}_{k+1}).
\end{split}
\end{equation*}
Note that $p^{11}$ and $p^{21}$ in the above equation should be replaced by corresponding entries in \Cref{eqn:elementwise-upd-P}.
\begin{equation*}
\gamma_{k+1}-\bar{\gamma}_{k+1}\approx \left[\frac{\partial \gamma}{\partial z},\frac{\partial \gamma}{\partial \theta}\right]\begin{bmatrix}
z-\bar{z} \\ \theta-\bar{\theta}
\end{bmatrix}
\end{equation*}

\subsection{partial derivative of $\gamma$}
The partial derivative for $\gamma_1$, $\gamma_2$, and $\gamma_3$ are as follows:
\begin{equation*}
\begin{split}
\begin{bmatrix}
\frac{\partial \gamma_1}{\partial z}\\
\frac{\partial \gamma_1}{\partial \theta}
\end{bmatrix}&=
\begin{bmatrix}
-\exp^{\alpha_1(\|x-\bar{z}\|^2_2-r^2)}\alpha_1(x-\bar{z})\\
0
\end{bmatrix},\\
\begin{bmatrix}
\frac{\partial \gamma_1}{\partial z}\\
\frac{\partial \gamma_1}{\partial \theta}
\end{bmatrix}&=
\begin{bmatrix}
-\sin(\bar{\psi_1})\\
\cos(\bar{\psi_1})\\
x_1\cos(\bar{\psi_1})+x_2\sin(\bar{\psi_1})-\bar{z}_1\cos(\bar{\psi_1})-\bar{z}_2\sin(\bar{\psi_1})
\end{bmatrix}\alpha_2(\gamma_2-1),\\
\begin{bmatrix}
\frac{\partial \gamma_1}{\partial z}\\
\frac{\partial \gamma_1}{\partial \theta}
\end{bmatrix}&=
\begin{bmatrix}
\sin(\bar{\psi_2})\\
-\cos(\bar{\psi_2})\\
-x_1\cos(\bar{\psi_2})-x_2\sin(\bar{\psi_2})+\bar{z}_1\cos(\bar{\psi_2})+\bar{z}_2\sin(\bar{\psi_2})
\end{bmatrix}\alpha_3(\gamma_3-1).
\end{split}
\end{equation*}
Then the derivative of $\gamma$ can be computed as:
\begin{equation*}
\begin{bmatrix}
\frac{\partial \gamma}{\partial z}\\
\frac{\partial \gamma}{\partial \theta}
\end{bmatrix}=
-\frac{1}{(\gamma_1\gamma_2\gamma_3)^2}\begin{bmatrix}
\frac{\partial \gamma_1}{\partial z}\gamma_2\gamma_3+\gamma_1\frac{\partial \gamma_2}{\partial z}\gamma_3+\gamma_1\gamma_2\frac{\partial \gamma_3}{\partial z}\\
\frac{\partial \gamma_1}{\partial \theta}\gamma_2\gamma_3+\gamma_1\frac{\partial \gamma_2}{\partial \theta}\gamma_3+\gamma_1\gamma_2\frac{\partial \gamma_3}{\partial \theta}
\end{bmatrix}.
\end{equation*}

\section{Sequential optimization framework}
The problem uses two-layer of optimization. In the first layer, a non-convex problem is solved and the solution is provided to the second layer, which uses a convex optimization. (NOTE: may need to compare with iterative LQR).
\subsection{nonconvex programming}
The purpose of this layer is to find a good reference state for cvxPlanner to linearize around. The formulation uses the one defined in \Cref{eqn:MPC}.

\textbf{simplification}:
\begin{itemize}
	\item objective: the covariance matrix is assumed constant in planning horizon.
	\item weights of gmm are assumed constant.
	\item mean propagation: open-loop using the system dynamics, no measurement is used.
	\item covariance propagation: compute the gamma assuming the mean of a gmm component as the target position to update the covariance of the corresponding gmm component. $\bar{\theta}$ takes the value of the initial guess.
\end{itemize}

\textbf{Initial solution}:
\begin{itemize}
	\item At the beginning of the planning, use straight line constant acceleration model to generate initial guess. Later can change to motion primitives and try multiple initial guesses (similar to what John Schulman's work does).
	\item When cvxPlanner is used, use the solution of cvxPlanner with one-step extrapolation as the initial guess for ngPlanner in next round.
\end{itemize}

\textbf{Possible changes}: 
\begin{itemize}
	\item whether using initial guess to approximate A, C.
	\item it is unclear to me whether I should us ngPlanner at all (after the first step). I may be able to use cvxPlanner only for the rest of whole search process.
\end{itemize}

\subsection{iterative convex programming formulation}
This layer uses sequential convex programming to plan a trajectory. 

\textbf{Simplification}:
\begin{itemize}
	\item use the convex relaxation of $0$-th order approximation of entropy in the objective function.
	\item linearize \cref{subeqn:rbt_dyn} around reference trajectory.
	\item linearize \cref{subeqn:est_upd} around reference trajectory.  Especially, the $K$ is assumed to use the reference value.
	\item A,C all uses the value of reference state.
\end{itemize}

\textbf{possible changes}:
\begin{itemize}
	\item the sensor FOV approximation is bad. only gives value 1 in very small state range.
\end{itemize}

\subsubsection{Approximating the Objective Function}
We can obtain the upper bound of \Cref{eqn:approx_obj} using Jensen's inequality:
\begin{align*}
&-\sum\limits_{k=1}^{N+1} \sum\limits_{i=1}^{L}w_i\log \sum\limits_{j=1}^L\mathcal{N}(\hat{x}^i_{k|k}|\hat{x}^j_{k|k},P^j_{k|k})\\
&\leq -\sum\limits_{k=1}^{N+1} \sum\limits_{i=1}^{L}w_i \sum\limits_{j=1}^L\log\mathcal{N}(\hat{x}^i_{k|k}|\hat{x}^j_{k|k},P^j_{k|k})\\
&=\sum\limits_{k=1}^{N+1} \sum\limits_{i=1}^{L}w_i \sum\limits_{j=1}^L\frac{(\hat{x}^i_{k|k}-\hat{x}^j_{k|k})^T[P^j_{k|k}]^{-1}(\hat{x}^i_{k|k}-\hat{x}^j_{k|k})}{2}+\log(2\pi)+\frac{\log(|P^j_{k|k}|)}{2}
\end{align*}
The upper bound is tight when all GMM components become equivalent.

Note that the first term is NOT a quadratic objective function, but it is convex! (matrix-fractional function).
This can be transformed into LMI as this:
\begin{align*}
(\hat{x}^i_{k|k}-\hat{x}^j_{k|k})^T[P^j_{k|k}]^{-1}(\hat{x}^i_{k|k}-\hat{x}^j_{k|k})&\leq t \iff\\
\begin{bmatrix}
P^j_{k|k} & \hat{x}^i_{k|k}-\hat{x}^j_{k|k}\\
(\hat{x}^i_{k|k}-\hat{x}^j_{k|k})^T & t
\end{bmatrix}&\geq 0,\qquad t\geq 0
\end{align*}
\textcolor{red}{However, the third term (negative log determinant) is a concave function.}
%So we can use a two-step procedure, making the objective function of "nice" form.
%This is motivated by the two-step procedure in the E-M algorithm.
%The first step (M(ean)-step) fixes $P^j_{k|k}$ using the result from the last iteration and solve for $\hat{x}^i_{k|k}$, $\hat{x}^j_{k|k}$. 
%The objective function is quadratic in $x$.
%The second step (C(ovariance)-step) fixes $\hat{x}^i_{k|k}$ using the result from the last iteration and solve for $P^j_{k|k}$. 
%The objective function is quadratic in $x$.
This means, I may have to turn to quadratic approximation...

\subsection{SCP}
merit function: the original formulation with nonlinear constraints imposed as penalty terms in objective function.
iterative linearization: use 1st order approximation for nonlinear objective function and nonlinear constraint terms in obj.


\section{possible extensions}
This section compiles the possible contributions I can make in this and other following works. The previous sections are the actual implementation of what I will do in this work.
\begin{enumerate}
	\item GSF with good weight and component number update law
		\begin{enumerate}
			\item GMM-PF: update PF and GMM at the same time, not running E-M to fit GMM for PF. One benefit of this is that we can always check the difference between PF and GMM and generate a better GMM if difference is big.
			\item when updating GMM, can we treat $\gamma=0$ as a rare event? Will Dirichlet process help?
			\item treat $\gamma=0$ and $\gamma=1$ as hybrid system. Then use GMM to model the mode switch? I think a little bit about this but seems difficult to do.
		\end{enumerate}
	\item efficient computation of the objective function
	\item how to represent and compute $\gamma$ (incorporating $b_t$ or just using a point estimate (e.g. MAP))
	\item incorporate negative info in a better way than $\gamma$.
	\item the way to do iterative planing: updating $\gamma$ in SQP or outside SQP; whether updating $w$. if not updating, can I obtain an upper bound of the error?
	\item control of nonholonomic vehicle
	\item make the problem a cvx optimization or some other form (e.g., proximal gradient) to better utilize the form of the problem.
\end{enumerate}
1,3,4 are the possible main contributions of the work.

\end{document}
