%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

%\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
\documentclass[journal]{IEEEtran}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

%\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphicx}
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{subcaption}
\usepackage[noadjust]{cite}
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath,amssymb,amsfonts,amsthm} % assumes amsmath package installed
\usepackage{algorithm,algpseudocode}
%\usepackage{booktabs}

% format for theorems etc.
\newtheorem{thm}{\bfseries Theorem}
\newtheorem{lem}{\bfseries Lemma}
\newtheorem{cor}{\bfseries Corollary}
\newtheorem{prop}{\bfseries Proposition}
\newtheorem{rem}{\bfseries Remark}

% format for argmin, argmax
\newcommand{\argmax}{\operatornamewithlimits{argmax}}

% format for cross-reference
\usepackage[capitalize]{cleveref}
\crefname{equation}{eq.}{eq.}
\Crefname{equation}{Eq.}{Eq.}
\crefname{thm}{theorem}{theorems}
\Crefname{thm}{Theorem}{Theorems}
\crefname{lem}{lemma}{lemmas}
\Crefname{lem}{Lemma}{Lemmas}
\crefname{cor}{corollary}{corollaries}
\Crefname{cor}{Corollary}{Corollaries}
\crefname{prop}{proposition}{propositions}
\Crefname{prop}{Proposition}{Propositions}
\crefname{rem}{remark}{remarks}
\Crefname{rem}{Remark}{Remarks}

%=====todonotes===== %
\usepackage{todonotes}
\usepackage{soul}
\definecolor{smoothgreen}{rgb}{0.7,1,0.7}
\sethlcolor{smoothgreen}

\newcommand{\todopara}[1]{\vspace{0px} %
	\todo[inline, color=black!10]{\textbf{[Paragraph:]} {#1}} %
}
\newcommand{\todonote}[1]{\vspace{0px} %
	\todo[inline, color=green!30]{\textbf{[Note:]} {#1}} %
}
\newcommand{\todoQ}[1]{\vspace{0px} %
	\todo[inline, color=orange!50]{\textbf{[Note:]} {#1}} %
}
\newcommand{\todohere}[1]{\hl{(\textbf{TODO:} #1)}}

\newcommand{\hidetodos}{
	\renewcommand{\todopara}[1]{}
	\renewcommand{\todonote}[1]{}
	\renewcommand{\todoQ}[1]{}
	\renewcommand{\todohere}[1]{}
	}


\title{\LARGE \bf
Distributed Bayesian filters for multi-robot network using latest-in-and-full-out exchange protocol of observations}


\author{Chang~Liu,~\IEEEmembership{Student Member,~IEEE,}
	Shengbo~Eben~Li,~\IEEEmembership{Member,~IEEE,}
	and~J.~Karl~Hedrick%~\IEEEmembership{Life~Fellow,~IEEE}% <-this % stops a space
	\thanks{*The first two authors, C. Liu and S. Li, have equally contributed to this research. }
	\thanks{Chang Liu and J. Karl Hedrick are with the Vehicle Dynamics \& Control Lab, Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA 94709, USA. Email: {\tt\small changliu@berkeley.edu, khedrick@me.berkeley.edu.}}% <-this % stops a space
	\thanks{S. Eben Li is with State Key Lab of Automotive Safety and Energy, Department of Automotive Engineering, Tsinghua University, Beijing, 100084, China. He was with  Department of Mechanical Engineering, University of California, Berkeley, as a visiting scholar. Email: {\tt\small lisb04@gmail.com.}}
}% <-this % stops a space
	%\thanks{Manuscript received April 19, 2005; revised January 11, 2007.}}

%\author{Chang Liu$^{1}$, Shengbo Eben Li$^{2}$ and J. Karl Hedrick$^{3}$% <-this % stops a space
%\thanks{*The first two authors, C. Liu and S. Li, have equally contributed to this research.}% <-this % stops a space
%\thanks{$^{1}$Chang Liu is with the Vehicle Dynamics \& Control Lab, Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA 94709, USA. Email: {\tt\small changliu@berkeley.edu}}%
%\thanks{$^{2}$Shengbo Eben Li is with the Department of Automotive Engineering, Tsinghua University, Beijing, 100084, China. He is currently working at Department of Mechanical Engineering, University of California, Berkeley as a visiting scholar. Email: {\tt\small lisb04@gmail.com}}%
%\thanks{$^{3}$J. Karl Hedrick is with the Vehicle Dynamics \& Control Lab, Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA 94709, USA. Email: {\tt\small khedrick@me.berkeley.edu}}%
%}


\begin{document}

%\hidetodos % hide all todos 

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%\setlength{\belowcaptionskip}{-10pt} % set the spacing between figure and text

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

This paper presents a measurement dissemination-based distributed Bayesian filtering (DBF) method for a multi-robot network by utilizing the Latest-In-and-Full-Out (LIFO) local exchange protocol of observations.
% for target search and tracking.
Different from statistics dissemination approaches that transmit posterior distributions or likelihood functions, each robot under LIFO only exchanges with neighboring robots a full communication buffer consisting of latest available measurements,
%receives the latest available measurements and then broadcasts full communication buffer to its neighborhood, 
which reduces the transmission burden between each pair of robots from the order of environmental size to that of robot number.
Under the condition of fixed and undirected topology, LIFO can guarantee non-intermittent dissemination of all observations over the network within finite time.
%, with each robot non-intermittently receiving observations of all others.
Two types of LIFO-based DBF algorithms are then derived to estimate individual posterior density function (PDF) for static and moving target, respectively. 
For the static target, each robot locally fuses the newly received observations while for the moving target, a set of historical observations is stored and updated. 
%Upon obtaining the latest available observations of all robots, an iterative Bayesian filtering procedure is applied that alternates between prediction and updating steps. 
The consistency and consensus of LIFO-based DBF are proved that estimated target position converges in probability to the true target position when the number of observations tends to infinity.
%the agreement between robots' estimated target position and the actual position.
The effectiveness of this method is demonstrated by numerical simulations.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
Distributed filtering that focuses on using a group of networked robots to collectively infer environment status has been used for various applications, such as intruder detection \cite{chamberland2007wireless}, pedestrian tracking \cite{wang2007wlan} and micro-environmental monitoring \cite{cao2008development}. 
Several techniques have been developed for distributed filtering.
For example, Olfati-Saber (2005) proposed a distributed Kalman filter (DKF) for estimating states of linear systems with Gaussian process and measurement noise \cite{2005distributed}.
Each DKF used additional low-pass and band-pass consensus filters to compute the average of weighted measurements and inverse-covariance matrices.
Madhavan et al. (2004) presented a distributed extended Kalman filter for nonlinear systems \cite{madhavan2004distributed}.
This filter was used to generate local terrain maps by using pose estimates to combine elevation gradient and vision-based depth with environmental features.
Gu (2007) proposed a distributed particle filter for Markovian target tracking over an undirected sensor network \cite{gu2007distributed}. 
Gaussian mixture models (GMM) were adopted to approximate the posterior distribution from weighted particles and the parameters of GMM were exchanged via average consensus filter.
As a generic filtering scheme for nonlinear systems and arbitrary noise distributions, distributed Bayesian filters (DBF) have received increasing interest during past years \cite{bandyopadhyay2014distributed,julian2012distributed}, which is also the focus of this study.
%This study focuses on developing a distributed Bayesian filter (DBF) that is applicable for state estimation of general nonlinear systems and the proposed DBF is applied to search and tracking (SAT) of both static and moving targets.

The design of distributed filtering algorithms is closely related to the communication topology of multi-robot network, which can be classified into two types: fusion center (FC)-based and neighborhood (NB)-based.
In the FC-based approaches, each robot uses a filter to estimate local statistics of environment status based on its own measurement.
The local statistics is then transmitted (possibly via multi-hopping) to a single FC, where a global posterior distribution (or statistical moments in DKF \cite{olfati2007consensus}) is calculated at each filtering cycle after receiving all local information \cite{zuo2006bandwidth,vemula2006target}.
%At each filtering cycle, fusion center calculates the global state estimate only after receiving latest local estimates of all robots \cite{zuo2006bandwidth,vemula2006target}.
% has been a common structure for distributed filtering, in which local information collected by robots is transmitted (possibly via multi-hopping) to the fusion center for forming global estimation \cite{zuo2006bandwidth,ribeiro2006bandwidth}. 
%FC-based DBF is efficient for estimation in that it can collectively utilize all robots' information and thus useful for applications that only require information at a single central unit, such as in environmental monitoring.
%However, FC-based DBF requires constant communication link between each robot and the center, which is challenging for applications of robots in vast or complex areas.
In the NB-based approaches, a set of robots execute distributed filters to estimate individual posterior distribution. 
The consensus of individual estimates is achieved by solely communicating statistics and/or observations within local neighbors of these robots.
%Only communication between neighboring agents is allowed.
The NB-based methods have become popular in recent years since they do not require complex routing protocols or global knowledge of the network and therefore are robust to topological changes and to link failures.
%, and thus suitable for networks with mobile agents.
%Besides, filtering is locally conducted on each robot, which requires less computation power compared to that in the fusion center.

%instead of communicating with a fusion center, each robot only exchanges information with neighboring robots and forms local estimation of the environment state. 
%NB-based DBF is advantageous over FC-based DBF in that no central unit is required, thus suitable for applications in which maintaining communication link between robots and center is challenging, such as in disaster situations.
%Besides, state estimation is locally conducted on each robot, which requires less computation power compared to that in the fusion center.

Nowadays, most studies on NB-based distributed filtering have mainly been on so-called \textit{statistics dissemination} strategy that each robot actually exchanges statistics, including posterior distributions and likelihood functions, with neighboring robots \cite{hlinka2013distributed}.
%\todohere{concern: this categorization is based on Hlinka's survery. Will this cause trouble? Besides, the name statistics dissemination and measurement dissemination are also from this survey. Any issues?}
This strategy can be further categorized into two types: leader-based and consensus-based. 
In the former, statistics is sequentially passed and updated along a path formed by active robots, called leaders.
Only leaders perform filtering based on its own and received measurements from local neighbors.
%\todohere{mention leader-based and consensus-based. 2 examples for leader-based and 3 examples for consensus-based.}
For example, Sheng et al. (2005) proposed a multiple leader-based distributed particle filter with Gaussian Mixer for target tracking \cite{sheng2005distributed}.
% to track multiple moving targets. 
Sensors are grouped into multiple uncorrelated cliques, in each of which a leader is assigned to perform particle filtering and the particle information is then exchanged among leaders.
%Distributed filters were run on a set of leader agents in uncorrelated sensor cliques and the particles were approximated as GMMs, the parameters of which were then exchanged among leaders for global estimation.
%In \cite{ram2007stochastic}, a circular topology that each sensor could only communicate with a fixed neighboring sensor was deployed for parameter estimation of a spatial field. 
%State estimates were updated using by sensors when passed along the circular topology Each sensor generates  based on that of the previous sensor and its own observation and sequentially passes the estimate to its neighbor.
In the consensus-based filters, every robot diffuses statistics among neighbors, via which global agreement of the statistics is achieved by using consensus protocols \cite{olfati2007consensus,ren2005consensus,jadbabaie2003coordination}.
% by which all robots exchange statistics and executes consensus algorithms with neighbors, as proposed in , for fusion of statistics.
%For example, \todohere{find example on likelihood exchange} Julian et al. (2012) proposed a weighted-linear-average algorithm for fusing\todohere{find a more detailed word} posterior functions of environment status \cite{julian2012distributed}.
% consensus-based distributed particle filter (DPF) that uses linear average consensus approach for fusing posterior functions of environment status. .
For example, Hlinka et al. (2012) proposed a distributed method for computing an approximation of the joint (all-sensors) likelihood function by means of weighted-linear-average consensus algorithm when local likelihood functions belong to the exponential family of distributions \cite{hlinka2012likelihood}.
Saptarshi et al. (2014) presented a Bayesian consensus filter that uses logarithmic opinion pool for fusing posterior distributions of the tracked target \cite{bandyopadhyay2014distributed}. 
%The proposed BCF can incorporate non-Gaussian uncertainties and nonlinearity in target dynamic models and measurement models.  
%The DPF can work even when the network diameter, the maximum in/out degree, and the number of robots are unknown.
Other examples can be found in \cite{julian2012distributed,beaudeau2012target}.
%There are other types of variants, for example, in \cite{ram2007stochastic}, a circular topology that each sensor can only communicate with a fixed neighboring sensor is deployed for parameter estimation of a spatial field. 
%Each sensor generates state estimate based on that of the previous sensor and its own observation and sequentially passes the estimate to its neighbor.
%who using the incremental Robbins-Monro gradient algorithm locally at each sensor.

Despite the popularity of statistics dissemination strategy, exchanging statistics can consume high communication resources.
Approximating statistics with parametric models, such as Gaussian Mixture Models \cite{sheng2005distributed}, can reduce communication burden to some extent.
Such a manipulation, however, increases the computation burden for each robot and also sacrifices the filtering accuracy due to the approximation.
%which can be infeasible in vast area or complex environment.
% such as marine search, seismological rescue, etc. 
One potential remedy is to disseminate measurement instead of statistics among neighbors, which has not been fully exploited in robotic community so far.
% strategy has been developed for NB-based DBFs, by which raw or quantized observations are exchanged among robots.
%This study focuses on the strategy of exchanging observations in the neighborhood of each robot, called the \textit{measurement dissemination-based} strategy, for the purpose of achieving a consensus of the probability density function (PDF) of the tracked target.  
One pioneering work was done by Coates et al. (2004), who used adaptive encoding of observations to minimize communication overhead \cite{coates2004distributed}.
Ribeiro et al. (2006) exchanged quantized observations along with error-variance limits considering more pragmatic signal models \cite{ribeiro2006bandwidth}.
A recent work was conducted by Djuric et al. (2011), who proposed to broadcast raw measurements to other agents, and therefore each robot has a complete set of observations of other robots for executing particle filtering \cite{djuric2011non}. 
%At each time instant, a subset of robots that are in proximity of the tracked targets share their observations for target position estimation.
% to all the remaining agents and apply local particle filter for target tracking 
%Another example can be found in \cite{rosencrantz2002decentralized}, in which both observations and statistics were exchanged among sensors for distributed surveillance of the environment.
The shortcoming of aforementioned works is that their communication topologies are assumed to be a complete graph that every pair of distinct robots is directly connected by a unique edge, which is not always feasible in reality. 

This paper extends existing works by introducing a Latest-In-and-Full-Out (LIFO) protocol into distributed Bayesian filters (DBF) for networked robots. 
Each robot is only allowed to broadcast observations to its neighbors by using single-hopping and then implements individual Bayesian filter locally after receiving transmitted observations.
The main benefit of using LIFO is on the reduction of communication burden, with the transmission data volume scaling linearly with the robot number, while a statistics dissemination-based strategy can suffer from the order of environmental size.
%In addition, LIFO spreads all robots' observations among the network via multi-hopping, ensuring each robot's access to all others' historical observations.
%After receiving observations from neighbors, each robot runs Bayesian filter locally for environment state estimation. 
The proposed LIFO-based DBF has following properties:
(1)	For a fixed and undirected network, LIFO guarantees the global dissemination of observations over the network in a non-intermittent manner.
%, with each robot non-intermittently receiving (delayed) observations of all other robots via local communication.
(2)	The corresponding DBF ensures the consistency of estimated target position, which also implies the consensus of target PDFs.
%which refers to the agreement between robots' estimates of target position and the true position of the target. 
%Moreover, consistency implies the consensus of robots' target PDFs.
%In this study, the consistency and consensus using LIFO-DBF is formally proved.

The rest of this paper is organized as follows: 
The problem of distributed Bayesian filtering is formulated in \cref{sec:prob_form}.
The LIFO-based DBF algorithm is described in \cref{sec:LIFO-dbf}, followed by the proof of consistency and consensus in \cref{sec:consist_proof}.
Simulation results are presented in \cref{sec:sim} and \cref{sec:conclu} concludes the paper.

\section{PROBLEM FORMULATION}\label{sec:prob_form}
Consider a network of $N$ robots in a bounded two-dimensional space $S$. 
Each robot is equipped with a binary sensor for environmental perception. Due to the limit of communication range, each robot can only exchange observations with its neighbors. 
The Bayesian filter is executed locally on each robot based on its own and received observations via single-hopping communication.

\subsection{Probabilistic Model of Binary Sensor}
%In this paper, distributed Bayesian filter is used to estimate the true target position by a network of binary sensors.
The binary sensor only gives two types of observation: $1$ if the target is detected, and $0$ if no target is detected. 
The observation of $i^\text{th}$ sensor at $k^\text{th}$ time step is denoted as $z^i_k$.
% and subjects to Bernoulli distribution $B(1,p_{i,k})$.
The likelihood function that the target is detected is
%The following likelihood function gives the probability for $i^\text{th}$ sensor to obtain $z^i_k$:
%\small\begin{equation}\label{eqn:bin_sensor}
%	P(z^i_k|x^T_k;x^R_k)=p^{z^i_k}_{i,k}(1-p_{i,k})^{1-z^i_k},
%\end{equation}\normalsize
%where $p_{i,k}=P(z^i_k=1|x^T_k;x^R_k)$; $x^T_k$ and $x^R_k$ denote the target and robot position at $k$, respectively.
\small\begin{equation}\label{eqn:bin_sensor1}
P(z^i_k=1|x^T_k;x^{R,i}_k)\in \left[0,1\right],\; x^T_k\in S, 
\end{equation}\normalsize
where $x^T_k$ denotes the target position; $x^{R,i}_k$ is the robot position.
%; $X^T$ represents the set of all possible target positions.
Correspondingly, the likelihood function that no target is detected is
\small\begin{equation}\label{eqn:bin_sensor0}
P(z^i_k=0|x^T_k;x^{R,i}_k)=1-P(z^i_k=1|x^T_k;x^{R,i}_k).
\end{equation}\normalsize
%\Cref{eqn:bin_sensor} actually defines a binary sensor model parameterized by $x^T_k$ and $x^R_k$.

The combination of \Cref{eqn:bin_sensor1} and \Cref{eqn:bin_sensor0} forms a binary sensor model parameterized by $x^T_k$ and $x^{R,i}_k$. 
The commonly used likelihood functions for binary sensor include Gaussian function \cite{bonnie2012modelling} and step function \cite{djuric2008target}.

\begin{rem}
	\normalfont
	Given the knowledge of current target and robot positions, current observation of each robot is conditionally independent from its own past observations and those of other robots.
\end{rem}

\begin{rem} 
	\normalfont
	The proposed LIFO protocol to be described in \cref{sec:LIFO-dbf} is applicable for both homogeneous and heterogeneous binary sensors. 
	A homogeneous model can simplify the analysis of completeness, while a heterogeneous model is more close to real sensing characteristics.
	In addition, it also works for other types of sensors, such as laser scanners and cameras.
\end{rem}
\subsection{Graphical Model of Communication Topology}
The robot network is always assumed to be connected, i.e., there exists a path, either direct or indirect, between every pair of robots.
Under this assumption, consider an undirected and fixed graph $G=(V,E)$, where $V=\left\lbrace 1,\dots,N\right\rbrace $ represents the index set of robots and $E=V\times V$ denotes the edge set. 
The adjacency matrix $M=\left[ m_{ij}\right] $ describes the communication topology of $G$:
\small\begin{equation*}
m_{ij}=\begin{cases}
1& \text{if}\;\left(i,j\right)\in E\\
0& \text{if}\;\left(i,j\right)\notin E
\end{cases},
\end{equation*} \normalsize
where $m_{ij}$ denotes the entity of adjacency matrix. 
The notation $m_{ij}=1$ indicates that a communication link exists between $i^\text{th}$ and $j^\text{th}$ robot and $m_{ij}=0$ indicates no communication between them.

The \textit{direct neighborhood} of $i^\text{th}$ robot is defined as $\mathcal{N}_i=\left\lbrace j|m_{ij}=1,\forall j\in\left\lbrace1,\dots,N \right\rbrace \right\rbrace $. 
All the robots in $\mathcal{N}_i$ can directly exchange information with $i^\text{th}$ robot. 
In addition to direct neighborhood, another set called \textit{available neighborhood} is defined as $\mathcal{Q}_i$, which contains indices of robots whose observations can be received by the $i^\text{th}$ robot given a specific observation exchange protocol. 
Note that in general $\mathcal{N}_i\subseteq\mathcal{Q}_i$.
%but when only single-hopping is allowed, $\mathcal{N}_i=\mathcal{Q}_i$. 
\cref{fig:com_topo} illustrates three types of typical topologies: ring \cite{lawton2003decentralized}, line \cite{liu2010simple}, and star \cite{thatte2008sensor}. 
All of them are undirected and connected topologies.

\begin{figure}%[thpb]
	\centering
	\includegraphics[width=0.47\textwidth]{figures/com_topo}
	\caption{Three types of topologies: (a) ring topology; (b) line topology; (c) star topology}
	\label{fig:com_topo}
\end{figure}

\subsection{Distributed Bayesian Filter for Multiple Robots}\label{subsec:dbf}
The generic distributed Bayesian filter (DBF) is introduced.
%, which is also stated in \cite{bandyopadhyay2014distributed} and \cite{julian2012distributed}. 
Each robot has its individual estimation of posterior density function (PDF) of target position, called \textit{individual PDF}. 
The individual PDF of $i^\text{th}$ robot at time $k$ is defined as
% ,z^{\mathcal{Q}_i}_{1:k})
$P^i_{pdf}(x^T_{k}|\mathbf{z}^i_{1:k})$, where $\mathbf{z}^i_{1:k}$ denotes the set of observations by $i^\text{th}$ robot and by robots in $\mathcal{Q}_i$ that are transmitted to $i^\text{th}$ robot by time $k$.
%from time $1$ through $k$ and $z^{\mathcal{Q}_i}_{1:k}$ means the set of observations by robots in $\mathcal{Q}_i$ that are transmitted to $i^\text{th}$ robot.
%Note that if the observation by $j^\text{th}(j\in \mathcal{Q}_i)$ robot at time $k'(k'\leq k)$ is not received by $i^\text{th}$ robot, the corresponding element $z^j_{k'}$ in $z^{\mathcal{Q}_i}_{1:k}$ is empty and thus not utilized for computing $i^\text{th}$ individual PDF.
The individual PDF is initialized as $P^i_{pdf}(x^T_0|\mathbf{z}^i_0)=P(x^T_0)$,
%$P^i_{pdf}(x^T_0|z^i_0,z^{\mathcal{Q}_i}_0)=P(x^T_0)$, 
given all available prior information including past experience and environmental knowledge. Under the DBF framework, the individual PDF is recursively estimated by two steps, i.e., prediction step and updating step.
 
\subsubsection{Prediction}
%The $i^\text{th}$ individual PDF at time $k-1$ is known, denoted as $P^i_{pdf}(x^T_{k-1}|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})$. 
%At time $k$, the prior individual PDF $P^i_{pdf}(x^T_{k-1}|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})$ is first predicted forward by using the Chapman-Kolmogorov equation:
At time $k$, the prior individual PDF $P^i_{pdf}(x^T_{k-1}|\mathbf{z}^i_{1:k-1})$ is first predicted forward by using the Chapman-Kolmogorov equation:
%\small\begin{align}\label{eqn:bayes_pred}
%&P^i_{pdf}(x^T_k|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})\notag\\
%&=\int P(x^T_k|x^T_{k-1})P^i_{pdf}(x^T_{k-1}|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})dx^T_{k-1}
%\end{align}\normalsize
\small\begin{equation}\label{eqn:bayes_pred}
P^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k-1})
=\int P(x^T_k|x^T_{k-1})P^i_{pdf}(x^T_{k-1}|\mathbf{z}^i_{1:k-1})dx^T_{k-1}, 
\end{equation}\normalsize
where $P(x^T_k|x^T_{k-1})$ is a Markov motion model of the target, independent of robot states. 
This model describes the state transition probability of the target from a prior state $x^T_{k-1}$ to posterior state $x^T_k$. 
Note that the target is static in many search applications, such as the indoor search for stationary objects \cite{kulich2014single}. 
For a static target, its Markov motion model is simplified to be
\small\begin{equation*}
P(x^T_k|x^T_{k-1})=\begin{cases}
1 & \text{if}\; x^T_k=x^T_{k-1}\\
0 & \text{if}\; x^T_k\neq x^T_{k-1}
\end{cases}.
\end{equation*}\normalsize
%and \Cref{eqn:bayes_pred} can be reduced to $P^i_{pdf}(x^T_{k}|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})=P^i_{pdf}(x^T_{k-1}|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})$.

\subsubsection{Updating}
The $i^\text{th}$ individual PDF is then updated by Bayes' formula using the set of newly received observations $\mathbf{z}^i_k$:
%\small\begin{align}\label{eqn:bayes_upd}
%&P^i_{pdf}(x^T_k|z^i_{1:k},z^{\mathcal{Q}_i}_{1:k})\notag\\
%&=K_iP^i_{pdf}(x^T_k|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})P(z^i_k|x^T_k)\prod\limits_{j\in\mathcal{Q}_i}P(z^j_k|x^T_k)
%\end{align}\normalsize
%\small\begin{equation}\label{eqn:bayes_upd}
%P^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k})
%=K_iP^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k-1})P(z^i_k|x^T_k)\prod\limits_{j\in\mathcal{Q}_i}P(z^j_k|x^T_k)
%\end{equation}\normalsize
\small\begin{equation}\label{eqn:bayes_upd}
P^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k})
=K_iP^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k-1})P(\mathbf{z}^i_k|x^T_k),
\end{equation}\normalsize
where $K_i$ is a normalization factor:
%\small\begin{align*}
%K_i=1/\int P^i_{pdf}(x^T_k|z^i_{1:k-1},z^{\mathcal{Q}_i}_{1:k-1})P(z^i_k|x^T_k)\prod\limits_{j\in\mathcal{Q}_i}P(z^j_k|x^T_k)dx^T_k
%\end{align*}\normalsize
%\small\begin{align*}
%K_i=1/\int P^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k-1})P(z^i_k|x^T_k)\prod\limits_{j\in\mathcal{Q}_i}P(z^j_k|x^T_k)dx^T_k
%\end{align*}\normalsize
\small\begin{align*}
K_i=1/\int P^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k-1})P(\mathbf{z}^i_k|x^T_k)dx^T_k.
\end{align*}\normalsize
and $P^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k})$ is called posterior individual PDF; $P(z^i_k|x^T_k)$ is the likelihood function of observation $z^i_k$, described in \Cref{eqn:bin_sensor1} and \Cref{eqn:bin_sensor0}.

\section{Distributed Bayesian Filter via Latest-In-and-Full-Out Protocol}\label{sec:LIFO-dbf}
This study proposes a Latest-In-and-Full-Out (LIFO) protocol for observation exchange and derives two corresponding distributed Bayesian filtering (DBF) algorithms, shorted as LIFO-DBF. 
The data communication in LIFO uses synchronized step as the execution of DBF.
In each step, LIFO only allows single-hopping communication within the direct neighborhood, but with the ability to broadcast observations of each robot to any other agents after a finite number of steps.
The individual PDF is predicted and updated in DBF after each LIFO cycle.
The theoretical analysis show that LIFO-DBF can ensure the consistency and consensus of distributed estimation while requiring much less communication burden than statistics dissemination-based methods. 

\subsection{Latest-In-and-Full-Out (LIFO) Protocol}\label{subsec:LIFO}
Under LIFO, each robot contains a communication buffer (CB) to store its latest knowledge of observations of all robots: 
\begin{equation*}
\mathbf{z}^{CB,i}_k=\left[ z^1_{k^i_1},\dots,z^N_{k^i_N}\right], 
\end{equation*}
where $z^j_{k^i_j}$ represents the observation made by ${j^\text{th}}$ robot at time $k^i_j$. 
Note that under LIFO, $\mathcal{Q}_i=\left\lbrace 1,\dots,N\right\rbrace \setminus \left\lbrace i\right\rbrace$, which will be proved in \Cref{cor1}.
At time $k$, $z^j_{k^i_j}$ is received and stored in ${i^\text{th}}$ robot CB, in which $k^i_j$ is the latest observation time of ${j^\text{th}}$ robot available to ${i^\text{th}}$ robot. Due to the communication delay, $k^i_j<k, \forall j\neq i$ and $k^i_i=k$ always holds.
The \textbf{LIFO protocol} is stated in \cref{alg:lifo}.

\begin{algorithm}
	\caption{LIFO Protocol}
	\label{alg:lifo}
	\begin{algorithmic}
		\State \textbf{(1)} Initialization:
		The CB of $i^\text{th}$ robot is initialized when $k=0$: 
		\begin{equation*}
		%$\begin{array}{c}
		z^j_{k^i_j}=\varnothing,\; k^i_j=0,\;j=1,\dots,N. 
		%\end{array}$\\
		\end{equation*}
		
		\State \textbf{(2)} At $k^\text{th}$ step for $i^\text{th}$ robot :		
		\State (2.1) Receiving Step:
		
		The $i^\text{th}$ robot receives all CBs of its direct neighborhood $\mathcal{N}_i$.
		The received CBs are totally $|\mathcal{N}_i|$ groups, each of which corresponds to the (k-1)-step CB of a robot in $\mathcal{N}_i$. 
		The received CB from $l^\text{th}$ ($l\in \mathcal{N}_i$) robot is denoted as
		\begin{equation*}
		\mathbf{z}^{CB,l}_{k-1}=\left[ z^1_{(k-1)^l_1},\dots,z^N_{(k-1)^l_N}\right],\; l\in\mathcal{N}_i.
		\end{equation*}
		
		\State (2.2) Observation Step: 
		
		The $i^\text{th}$ robot updates $z^j_{k^i_j}\,(j=i)$ by its own observation at current step:
		\begin{equation*}
		z^j_{k^i_j}=z^i_k,\;k^i_j=k,\;\text{if }j=i.
		\end{equation*}
		
		\State (2.3) Comparison Step:
		
		The $i^\text{th}$ robot updates other elements of its own CB, i.e., $z^j_{k^i_j}\,(j\neq i)$, by selecting the latest information among all received CBs from $\mathcal{N}_i$. For all $j\neq i$,
		\small\begin{align*}
		l_\text{latest}&=\argmax_{l\in \mathcal{N}_i,\;i}\left\lbrace\left(k-1\right)^i_j,\left(k-1\right)^l_j  \right\rbrace\\
		z^j_{k^i_j}&=z^j_{\left(k-1\right)^{l_\text{latest}}_j},\; k^i_j=\left(k-1\right)^{l_\text{latest}}_j. 
		\end{align*} \normalsize
		
		\State (2.4) Sending Step:
		
		The $i^\text{th}$ robot broadcasts its updated CB to all of its neighbors defined in $\mathcal{N}_i$.
		%\bottomrule
		%\end{tabular}
				
		\State \textbf{(3)} $k\leftarrow k+1$ until stop. %$\hfill\blacksquare$
	\end{algorithmic}
\end{algorithm}





%The \textbf{LIFO protocol} is stated as follows:
%
%%\begin{tabular}{l}
%%\toprule
%%LIFO Algorithm\\
%%\midrule
%(1) Initialization:
%The buffer of $i^\text{th}$ robot is initialized when $k=0$: 
%\begin{equation*}
%%$\begin{array}{c}
%	z^j_{k^i_j}=\emptyset,\; k^i_j=0,\;j=1:N
%%\end{array}$\\
%\end{equation*}
%
%(2) At $k^\text{th}$ step for $i^\text{th}$ robot :
%
%(2.1) Receiving Step:
%
%The $i^\text{th}$ robot receives all CBs of its direct neighborhood $\mathcal{N}_i$.
%The received CBs are totally $|\mathcal{N}_i|$ groups, each of which corresponding to the (k-1)-step CB of a robot in $\mathcal{N}_i$. 
%The received CB from $l^\text{th}$ ($l\in \mathcal{N}_i$) robot is denoted as
%\begin{equation*}
%\mathbf{z}^l_{k-1}=\left[ z^1_{(k-1)^l_1},\dots,z^N_{(k-1)^l_N}\right],\; l\in\mathcal{N}_i
%\end{equation*}
%
%(2.2) Observation Step: 
%
%The $i^\text{th}$ robot updates $z^j_{k^i_j}\,(j=i)$ by its own observation at current step:
%\begin{equation*}
%z^j_{k^i_j}=z^i_k,\;k^i_j=k,\;\text{if }j=i.
%\end{equation*}
%
%(2.3) Comparison Step:
%
%The $i^\text{th}$ robot updates other elements of its own CB, i.e., $z^j_{k^i_j}\,(j\neq i)$, by selecting the latest information among all received CBs from $\mathcal{N}_i$. For all $j\neq i$,
%\begin{align*}
%l_\text{latest}&=\argmax_{l\in \mathcal{N}_i,i}\left\lbrace\left(k-1\right)^i_j,\left(k-1\right)^l_j  \right\rbrace\\
%z^j_{k^i_j}&=z^j_{\left(k-1\right)^{l_\text{latest}}_j},\; k^i_j=\left(k-1\right)^{l_\text{latest}}_j
%\end{align*} 
%
%(2.4) Sending Step:
%
%The $i^\text{th}$ robot broadcasts its updated CB to all of its neighbors defined in $\mathcal{N}_i$.
%%\bottomrule
%%\end{tabular}
%
%(3) $k\leftarrow k+1$ until stop $\hfill\blacksquare$\\

\begin{figure}%[thpb]
	\centering
	\includegraphics[width=0.48\textwidth]{figures/data_exchange}
	\caption{Example of LIFO with three robots using line communication topology}
	\label{fig:LIFO}
\end{figure}


\cref{fig:LIFO} illustrates the LIFO cycles with 3 robots using a line topology. 
Two facts can be noticed in \cref{fig:LIFO}: (1) all robot CBs are filled within 3 steps, which means under LIFO each robot has a maximum delay of 2 steps for receiving observations from other robots; (2) once filled, CBs are updated non-intermittently, which means each robot continuously receives new observations of other robots. Extending the two facts to a network of $N$ robots, we have the following proposition:
\medskip
\begin{prop}\label{prop1}
	\normalfont
For a fixed and undirected network of $N$ robots, LIFO uses the shortest path(s) between $i^\text{th}$ and $j^\text{th}$ robot to exchange observation, the length of which is the delay $\tau_{i,j}$ between these two robots.
\end{prop}
\begin{proof} 
Without loss of generality, assume that there is a unique shortest path between $i$ and $j$, denoted by $T^{j,i}_{n^*}=\left(v_1,\dots,v_{n^*}\right)$, with $v_1=j,v_{n^*}=i,v_{m+1}\in\mathcal{N}_{v_m}$. 
Then, the distance between $i$ and $j$ is $d(j,i)=n^*-1$. 
The following mathematical induction will prove \Cref{prop1}.

Step (1): When $d(j,i)=1$, $j\in\mathcal{N}_i$ and $j$ can directly send $z^j_k$ to $i$. Then $z^j_k$ is stored in $i^\text{th}$ CB at time $k+1$, i.e., $\tau_{i,j}=1$. 
\Cref{prop1} holds for $d(j,i)=1,\,\forall i,j\in\left\lbrace 1,\dots,N\right\rbrace $.

Step (2): Suppose that \Cref{prop1} holds for $d(j,i)=s,\,s\geq 2,\,\forall i,j\in\left\lbrace 1,\dots,N\right\rbrace$. 
Then for $d(j,i)=s+1$, i.e., $n^*=s+2$, by the Bellman's principle of optimality, the path $T^{j,l}_{n^*-1}=\left(v_1,\dots,v_{n^*-1}\right)$ is a shortest path between $j$ and $l$, where $v_{n^*-1}=l$ and $i\in \mathcal{N}_l$. 
The assumption that \Cref{prop1} holds for $d(j,i)=s$ implies that $z^j_k$ is received and stored in $l^\text{th}$ robot's CB at time $k+s$. 
Since $i\in\mathcal{N}_l$, $i^\text{th}$ robot receives $z^j_k$ at $k+s+1$. 
For any other path $T^{j,i}_{n}=\left(v_1,\dots,v_{n}\right)$ with $n>n^*$, $z^j_k$ cannot be received by $i$ earlier than $k+s+1$. 
Therefore $\tau_{i,j}=s+1$. 
This proves the \Cref{prop1} for $d(j,i)=s+1$.
\end{proof}
%\vspace{\baselineskip}
\medskip
\begin{cor}\label{cor1}
	\normalfont
For the same topology in \Cref{prop1}, all elements in $\mathbf{z}^{CB,i}_k$ under LIFO become filled when $k\geq N$, i.e., $\mathcal{Q}_i = \left\lbrace1,\dots,N \right\rbrace \setminus \left\lbrace i\right\rbrace $.	
\end{cor}
\begin{proof}
In a network of $N$ robots, the maximal length of shortest paths is no greater than $N-1$. Based on \Cref{prop1}, $\tau_{i,j}\leq N-1$ and thus all elements of $\mathbf{z}^{CB,i}_k$ become filled when $k\geq N$.
\end{proof}
\medskip
\begin{cor}\label{cor2}
	\normalfont
For the same topology in \Cref{prop1}, once all elements in $\mathbf{z}^{CB,i}_k$ are filled, the updating of each element is non-intermittent. 	
\end{cor}
\begin{proof}
For a network with fixed topology, shortest path(s) between any pair of nodes are fixed. 
Therefore, based on \Cref{prop1}, $\tau_{i,j}$ is constant and the updating of each element in $\mathbf{z}^{CB,i}_k$ is non-intermittent.
\end{proof}
\medskip
\begin{rem}
	\normalfont
	Compared to statistics dissemination, LIFO is generally more communication-efficient for distributed filtering. 
	To be specific, consider an $M\times M$ grid environment with a network of $N$ robots, the transmitted data of LIFO between each pair of robots are only the CB of each robot and corresponding robot positions where observations were made, the length of which is $O(N)$. 
	On the contrary, the length of transmitted data for a statistics dissemination approach that transmits unparameterized posterior distributions or likelihood functions is $O(M^2)$, which is in the order of environmental size. 
	Since $M$ is generally much larger than $N$ in applications such as target localization, LIFO requires much less communication resources.
\end{rem}

\subsection{Algorithm of LIFO-DBF for Static Target}\label{subsec:LIFO-dbf-sta-tar} 

This section derives the LIFO-DBF algorithm for localizing a static target. 
Each robot stores last-step individual PDF, i.e., $P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k-1})$. 
According to \Cref{cor2}, $\mathbf{z}^i_k=\mathbf{z}^{CB,i}_k$ and $\mathbf{z}^{i}_{1:k}=\mathbf{z}^{CB,i}_{1:k}=\left[ z^1_{1:k^i_1},\dots,z^N_{1:k^i_N}\right]$.
The assumption of static target can simplify the Bayesian filter as the prediction step becomes unnecessary. 
Therefore, the $i^\text{th}$ individual PDF is only updated by 
\small\begin{align}\label{eqn:LIFO-dbf-sta-tar}
P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})&=K_iP^i_{pdf}(x^T_k|\mathbf{z}^i_{1:k-1})P(\mathbf{z}^i_k|x^T_k)\notag\\
&=K_iP^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k-1})\prod\limits_{j=1}^{N}P(z^j_{k^i_j}|x^T), 
\end{align}\normalsize

%\small\begin{equation}\label{eqn:LIFO-dbf-sta-tar}
%P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})=K_iP^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k-1})\prod\limits_{j=1}^{N}P(z^j_{k^i_j}|x^T)
%\end{equation}\normalsize
where
\small\begin{equation*}
K_i=1/\int P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k-1})\prod\limits_{j=1}^{N}P(z^j_{k^i_j}|x^T)dx^T. 
\end{equation*}\normalsize

\subsection{Algorithm of LIFO-DBF for Moving Target}\label{subsec:LIFO-dbf-mov-tar}
This section derives the LIFO-DBF for localizing a moving target. 
Instead of storing last-step PDF, at time $k$ each robot maintains an individual PDF of time $(k-N)$ and a collection of historical observations, called the \textit{record set}, from time $(k-N+1)$ to $k$. 
The $i^\text{th}$ individual PDF is then alternatively predicted and updated by using aforementioned Bayesian filter (\Cref{eqn:bayes_pred} and \Cref{eqn:bayes_upd}) from $(k-N)$ to $k$.
\cref{fig:LIFO-DBF} illustrates the LIFO-DBF procedure for the $1^\text{st}$ robot as an example.
With a line topology, the record set of $1^\text{st}$ robot is shown as a triangle.
% shape formed by squares that contain observations from $(k-N+1)$ to $k$.

Let $\Omega^i_{\xi}\,\left(\xi=1,\dots,N\right) $ denote the index set of robots whose observation at time $(k-N+\xi)$ is stored in $i^\text{th}$ robot's record set. 
The \textbf{LIFO-DBF algorithm} for moving target is then stated in \cref{alg:lifo-dbf}.

\begin{figure}%[thpb]
	\centering
	\includegraphics[width=0.45\textwidth]{figures/DBF_demo}
	\caption{Example of LIFO-DBF for $1^\text{st}$ robot at time $k$. 	 
		Networked robots take a line topology, shown in the top. 
		The stored individual PDF is $ P^1_{pdf}(k-N)$.
		The robot first calculates $ P^1_{virt}(k-N+1)$ using DBF and stores it as $ P^1_{pdf}(k-N+1)$. 
		Repeating DBF until obtaining $ P^1_{pdf}(k)$, which is then used as the target PDF estimation of $1^\text{st}$ robot at time $k$.
		In this example, $\Omega^1_{\xi}=\left\lbrace 1,2,\dots,N+1-\xi\right\rbrace $, $\xi=1,\dots,N$.}
	\label{fig:LIFO-DBF}
\end{figure}

%\begin{enumerate}
%For $i^\text{th}$ robot at $k^\text{th}$ step:
%
%	\textbf{(1)} The stored individual PDF for time $(k-N)$ is:
%	\small\begin{equation*}
%		P^i_{pdf}(x^T_{k-N}|z^1_{1:k-N},\dots,z^N_{1:k-N})
%	\end{equation*}\normalsize
%	
%	\textbf{(2)} Initialize a virtual PDF by assigning the individual PDF to it:
%	\small\begin{equation*}
%		P^i_{virt}(x^T_{k-N})=P^i_{pdf}(x^T_{k-N}|z^1_{1:k-N},\dots,z^N_{1:k-N})
%	\end{equation*}\normalsize
%		
%	\textbf{(3)} From $\xi=1$ to $N$, repeat two steps of Bayesian filtering:
%%	\begin{enumerate}
%%		\item 
%
%		(3.1) Prediction 
%		\small\begin{align*}
%		&P_{virt}^{pre}(x^T_{k-N+\xi})\\=&\int P(x^T_{k-N+\xi}|x^T_{k-N+\xi-1})P^i_{virt}(x^T_{k-N+\xi-1})dx^T_{k-N+\xi-1}
%		\end{align*} \normalsize
%				
%%		\item 
%		(3.2) Updating
%		\small\begin{gather*}
%		P^i_{virt}(x^T_{k-N+\xi})=K_\xi P_{virt}^{pre}(x^T_{k-N+\xi})\prod\limits_{j\in\Omega^i_{\xi}}P(z^j_{k-N+\xi}|x^T_{k-N+\xi})\\
%		K_\xi=1/\int P_{virt}^{pre}(x^T_{k-N+\xi})\prod\limits_{j\in\Omega^i_{\xi}}P(z^j_{k-N+\xi}|x^T_{k-N+\xi})dx^T_{k-N+\xi}
%		\end{gather*} \normalsize
%%	\end{enumerate}
%	
%	\textbf{(4)} Store the first-step virtual PDF as the individual PDF for time $(k-N+1)$
%	\begin{equation*}
%		P^i_{pdf}(x^T_{k-N+1}|z^1_{1:k-N+1},\dots,z^N_{1:k-N+1})=P^i_{virt}(x^T_{k-N+1}).
%	\end{equation*}
%	$\hfill\blacksquare$
%\end{enumerate}
%1)	The stored individual PDF for $(k-N)^\text{th}$ step is $ P^i_{pdf}(x^T_{k-N}|z^1_{1:k-N},\dots,z^N_{1:k-N})$.
%
%2)	Initialize a virtual PDF by assigning the individual PDF to it:
%$P_{virt}(x^T_{k-N})=P^i_{pdf}(x^T_{k-N}|z^1_{1:k-N},\dots,z^N_{1:k-N})$
%
%3)	From $\xi=1$ to N, repeat two steps of Bayesian filtering
%(a)	Prediction 
%\begin{align*}
%&P_{virt}^{pre}(x^T_{k-N+\xi})\\=&\int P(x^T_{k-N+\xi}|x^T_{k-N+\xi-1})P_{virt}(x^T_{k-N+\xi-1})dx^T_{k-N+\xi-1}
%\end{align*} 
%(b)	Updating
%\begin{gather*}
%P_{virt}(x^T_{k-N+\xi})=K_\xi P_{virt}^{pre}(x^T_{k-N+\xi})\prod\limits_{j\in\Omega^i_{k-N+\xi}}P(z^j_{k_N+\xi|x^T_{k-N+\xi}})\\
%K_\xi=1/\int P_{virt}^{pre}(x^T_{k-N+\xi})\prod\limits_{j\in\Omega^i_{k-N+\xi}}P(z^j_{k-N+\xi}|x^T_{k-N+\xi})dx^T_{k-N+\xi}
%\end{gather*} 
%  
%4)	Store the first-step virtual PDF as the $(k-N+1)^\text{th}$ individual PDF: $P^i_{pdf}(x^T_{k-N+1}|z^1_{1:k-N+1},\dots,z^N_{1:k-N+1})=P_{virt}(x^T_{k-N+1}).$ 
%The individual PDF of $i^\text{th}$ robot at time $k$ is $P^i_{virt}(x^T_k)$.
\medskip
\begin{rem}
	\normalfont
	For the static target, each robot only needs current step CB to update individual PDFs. 
	Therefore, besides storing individual PDFs, only current-step CB is stored in robot memory and all historical CBs can be discarded, which means that the size of occupied memory is $O(N)$. 
	On the contrary, for the moving target, each robot needs to store a triangular matrix of historical observation 
%	(except current step CB) 
	with size of $O(N^2)$ and an individual PDF with size $O(M^2)$, which means that the size of occupied memory in each robot is $O(M^2+N^2)$.
\end{rem}

\section{Proof of Consistency and Consensus}\label{sec:consist_proof}
This section proves consistency and consensus of LIFO-DBF. 
Only proofs for localizing static target are presented, including both static and moving robots.
The proof of LIFO-DBF for moving target is similar to that of static target by considering the dynamic model of the target, which is omitted here. 

%Considering $S$ is finite and $x^{T^*}$ is the true location of target, define an \textit{equivalent-location} set $X^T_{eq}\subseteq S$ such that 
%\small\begin{equation*}
%X^T_{eq}=\left\lbrace x^T\in S\arrowvert P(z_k|x^{T})=P(z_k|x^{T^*}),\; \forall z_k\in \left\lbrace 0,1\right\rbrace\right\rbrace ,
%\end{equation*}\normalsize
%i.e., $x^T\in X^T_{eq}$ gives the same observation likelihood as $x^{T^*}$ for given robot positions.
%%for any two parameters in $X^T_{eq}$, the sensor model with one of these two parameters generates equivalent probability value for the same observation $z_k$
%Since $S$ is finite, $X^T_{eq}$ is also finite. 
%%Let $X^T_{eq,1},\dots,X^T_{eq,u}$ denote all equi-parameter sets that partition $X^T$ such that following properties hold:
%%\begin{enumerate}
%%	\item $\bigcup^u_{i=1} X^T_{eq,i}= X^T$
%%	\item $X^T_{eq,i}\cap X^T_{eq,j}=\emptyset,\;i,j\in \left\lbrace 1,\dots,u\right\rbrace ,i\neq j.$
%%\end{enumerate}
%%Without loss of generality, assume $x^{T^*}\in X^T_{eq,1}$, where $x^{T^*}$ denotes the actual position of the target. 
%
%%\todohere{double check if the following examples for equi-parameter set are accurate}
%
%%\begin{rem}
%%	the equivalent-location set depends on the property of the sensor. 
%%	For example, for a laser scanner with high-fidelity sensing capability, each equivalent-location set contains only a small number of target positions.
%	The reason to introduce equivalent-location set is that ghost target might exist in some special robot arrangement and sensor types.
%	For example, for undirected binary sensors that are linearly arranged, a ghost target can exist at the mirror position of the true target.
%	When sensors are overlapped at a single point, ghost targets can exist on a circle that contains the true target.
%	In theory, DBF cannot rule out ghost targets in such cases and prior knowledge is needed for further clarification.
%%	Therefore, this study only proves the convergence to the equivalent-location set rather to the true location.
%	However, by using high-fidelity sensors, such as cameras and laser scanners, and multiple observations from different robot placements, equi-location set can be reduced to only contain true location of target.
	
%\end{rem}

\begin{algorithm}
	\caption{LIFO-DBF Algorithm}\label{alg:lifo-dbf}
	\begin{algorithmic}
		\State For $i^\text{th}$ robot at $k^\text{th}$ step:
		\State After updating CB by \cref{alg:lifo},	
		\State \textbf{(1)} The stored individual PDF for time $(k-N)$ is:
		\small\begin{equation*}
		P^i_{pdf}(x^T_{k-N}|z^1_{1:k-N},\dots,z^N_{1:k-N})
		\end{equation*}\normalsize		
		\State\textbf{(2)} Initialize a virtual PDF by assigning the individual PDF to it:
		\small\begin{equation*}
		P^i_{virt}(x^T_{k-N})=P^i_{pdf}(x^T_{k-N}|z^1_{1:k-N},\dots,z^N_{1:k-N})
		\end{equation*}\normalsize		
		\State\textbf{(3)} From $\xi=1$ to $N$, repeat two steps of Bayesian filtering:
		%	\begin{enumerate}
		%		\item 
		
		\State(3.1) Prediction 
		\small\begin{align*}
		&P_{virt}^{pre}(x^T_{k-N+\xi})\\=&\int P(x^T_{k-N+\xi}|x^T_{k-N+\xi-1})P^i_{virt}(x^T_{k-N+\xi-1})dx^T_{k-N+\xi-1}
		\end{align*} \normalsize
		
		%		\item 
		\State(3.2) Updating
		\small\begin{gather*}
		P^i_{virt}(x^T_{k-N+\xi})=K_\xi P_{virt}^{pre}(x^T_{k-N+\xi})\prod\limits_{j\in\Omega^i_{\xi}}P(z^j_{k-N+\xi}|x^T_{k-N+\xi})\\
		K_\xi=1/\int P_{virt}^{pre}(x^T_{k-N+\xi})\prod\limits_{j\in\Omega^i_{\xi}}P(z^j_{k-N+\xi}|x^T_{k-N+\xi})dx^T_{k-N+\xi}
		\end{gather*} \normalsize
		%	\end{enumerate}
		
		\State(3.3) When $\xi=1$, store the virtual PDF as the individual PDF for time $(k-N+1)$
		\begin{equation*}
		P^i_{pdf}(x^T_{k-N+1}|z^1_{1:k-N+1},\dots,z^N_{1:k-N+1})=P^i_{virt}(x^T_{k-N+1}).
		\end{equation*}
		
		\State\textbf{(4)} Individual PDF of $i^\text{th}$ robot at time $k$ is
		$P^i_{pdf}(x^T_{k}|\mathbf{z}^{i}_{1:k})=P^i_{virt}(x^T_k)$.		
	\end{algorithmic}
\end{algorithm}

\subsection{Proof for static robots}
Considering $S$ is finite and $x^{T^*}$ is the true location of target, the consistency of LIFO-DBF for static robots is stated as follows: 
%\todohere{converge to a set or treat the PDF as a r.v.?}
\begin{thm}\label{thm:LIFO-dbf-sta-tar}
	When robots are static, the estimated target position converges to the true position of target in probability using LIFO-DBF, i.e.,
%	the set of estimated target position of each robot converges to $ X^T_{eq}$ in probability using LIFO-DBF when the number of observations tends to infinity, i.e.,
	\small\begin{equation*}
	\lim\limits_{k\rightarrow \infty}
	P(x^T=x^{T^*}|\mathbf{z}^{i}_{1:k})=
%	\begin{cases}
%	1 & \text{if}\; i=1\\
%	0 & \text{if}\; i\neq 1
%	\end{cases},\;
	1,\;i=1,\dots,N.
	\end{equation*}\normalsize
%	where $\mathbf{z}^{CB,i}_{1:k}=\left[z^1_{1:k^i_1},\dots,z^N_{1:k^i_N}\right] $.
%	, $\left\lbrace k_1,\dots,k_N\right\rbrace $ are the timestamps of the $i^\text{th}$ robot's latest knowledge of all robots' observations.
\end{thm}

\begin{proof}	
Considering the conditional independence of observations given $x^T\in S$, the batch form of DBF at $k^\text{th}$ step is:
\small\begin{subequations}
	\begin{align*}
		P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})&=P^i_{pdf}(x^T|z^1_{1:k^i_1},\dots,z^N_{1:k^i_N})\\
		&=\frac{P^i_{pdf}(x^T)\prod\limits_{j=1}^{N}\prod\limits_{l=1}^{k^i_j}P(z^j_l|x^T)}{\sum\limits_{x^T\in S}P^i_{pdf}(x^T)\prod\limits_{j=1}^{N}\prod\limits_{l=1}^{k^i_j}P(z^j_l|x^T)},
	\end{align*}
\end{subequations}\normalsize
where $P^i_{pdf}$ is $i^\text{th}$ initial individual PDF. 
It is known from \Cref{cor1} and \Cref{cor2} that $k-N<k^i_j\leq k$.
\addtocounter{equation}{-1}\\

Comparing $P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})$ with $P^i_{pdf}(x^{T^*}|\mathbf{z}^{i}_{1:k})$ yields
\small\begin{equation}\label{eqn:cmp}
\frac{P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^{i}_{1:k})}=\frac{P^i_{pdf}(x^T)\prod\limits_{j=1}^{N}\prod\limits_{l=1}^{k^i_j}P(z^j_l|x^T)}{P^i_{pdf}(x^{T^*})\prod\limits_{j=1}^{N}\prod\limits_{l=1}^{k^i_j}P(z^j_l|x^{T^*})}.
\end{equation}\normalsize

Take the logarithm of \Cref{eqn:cmp} and average it over $k$ steps:
\small\begin{equation}\label{eqn:cmp_log}
 \frac{1}{k}\ln\frac{P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^{i}_{1:k})}=\frac{1}{k}\ln\frac{P^i_{pdf}(x^T)}{P^i_{pdf}(x^{T^*})}+\sum\limits_{j=1}^{N}\frac{1}{k}\sum\limits_{l=1}^{k^i_j}\ln\frac{P(z^j_l|x^T)}{P(z^j_l|x^{T^*})}.
\end{equation}\normalsize

Since $P^i_{pdf}(x^T)$ and $P^i_{pdf}(x^{T^*})$ are bounded, then
\small\begin{equation}\label{eqn:cmp_lim1}
\lim\limits_{k\rightarrow \infty}\frac{1}{k}\ln\frac{P^i_{pdf}(x^T)}{P^i_{pdf}(x^{T^*})}= 0.
\end{equation}\normalsize

The binary observations subject to Bernoulli distribution $B(1,p_j)$, yielding
\small\begin{equation*}
P(z^j_l|x^T)=p^{z^j_l}_j(1-p_j)^{1-z^j_l}, 
\end{equation*}\normalsize
where $p_j=P(z^j_l=1|x^T)$. 
Utilizing the facts: (1) $z^j_l$ are conditionally independent samples from $B(1,p_j^*)$ and (2) $k-N<k^i_j\leq k$, the law of large numbers yields
\small\begin{equation*}
%\lim\limits_{k\rightarrow \infty}
\frac{1}{k}\sum\limits_{l=1}^{k^i_j}z^j_l\overset{P}{\longrightarrow}p^*_j,\quad 
%\lim\limits_{k\rightarrow\infty}
\frac{1}{k}(k^i_j-\sum\limits_{l=1}^{k^i_j}z^j_l)\overset{P}{\longrightarrow}1-p^*_j, 
\end{equation*}\normalsize
where $p_j^*=P(z^j_l=1|x^{T^*})$ and ``$\overset{P}{\longrightarrow}$" denotes ``convergence in probability''.
Then, 
\small\begin{equation}\label{eqn:cmp_lim2}
%\lim\limits_{k\rightarrow \infty}
\frac{1}{k}\sum\limits_{l=1}^{k_j}\ln\frac{P(z^j_l|x^T)}{P(z^j_l|x^{T^*})}\overset{P}{\longrightarrow}p^*_j\ln \frac{p_j}{p^*_j}+(1-p^*_j)\ln \frac{1-p_j}{1-p^*_j}. 
\end{equation}\normalsize

Note that the right-hand side of \Cref{eqn:cmp_lim2} achieves maximum value 0 if and only if $p_j=p_j^*$. 
Define 
\small\begin{equation*}
c(x^T)=\sum\limits_{j=1}^{N}p^*_j\ln \frac{p_j}{p^*_j}+(1-p^*_j)\ln\frac{1-p_j}{1-p^*_j}.
\end{equation*}\normalsize

Considering \Cref{eqn:cmp_lim1} and \Cref{eqn:cmp_lim2}, the limit of \Cref{eqn:cmp_log} is
\small \begin{equation}\label{eqn:lim}
% \lim\limits_{k\rightarrow \infty}
 \frac{1}{k}\ln\frac{P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^{i}_{1:k})}\overset{P}{\longrightarrow}c(x^T).
% \sum\limits_{j=1}^{N}p^*_j\ln \frac{p_j}{p^*_j}+(1-p^*_j)\ln \frac{1-p_j}{1-p^*_j}
\end{equation}\normalsize
 
It follows from \Cref{eqn:lim} that
\small\begin{equation}\label{eqn:lim2}
\frac{P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^{i}_{1:k})e^{c(x^T)k}}\overset{P}{\longrightarrow}1. 
\end{equation}\normalsize

Define the set $\bar{X}^T=S\setminus \left\lbrace x^{T^*}\right\rbrace$ and $c_M=\max\limits_{x^T\in\bar{X}^T}c(x^T)$.
Then $c_M<0$.
Summing \Cref{eqn:lim2} over $\bar{X}^T$ yields
\small\begin{equation}\label{eqn:lim3}
\frac{\sum\limits_{x^T\in \bar{X}^T}P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})e^{\left[c_M-c(x^T)\right]k}}{{P^i_{pdf}(x^{T^*}|\mathbf{z}^{i}_{1:k})}e^{c_Mk}}\overset{P}{\longrightarrow} |\bar{X}^T|, 
\end{equation}\normalsize
where $|\bar{X}^T|$ denotes the cardinality of $\bar{X}^T$.

Since $c_M<0$,  ${P^i_{pdf}(x^{T^*}|\mathbf{z}^{i}_{1:k})}e^{c_Mk}{\longrightarrow}0$, \Cref{eqn:lim3} implies
\begin{equation}\label{eqn:lim4}
\sum\limits_{x^T\in \bar{X}^T}P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})e^{\left[c_M-c(x^T)\right]k}\overset{P}{\longrightarrow}0. 
\end{equation}

Utilizing the relation 
\begin{equation*}
0\leq P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})\leq P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})e^{\left[c_M-c(x^T)\right]k},
\end{equation*}
it can be derived from \Cref{eqn:lim4} that
\small\begin{equation*}
\sum\limits_{x^T\in \bar{X}^T}P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})\overset{P}{\longrightarrow} 0. 
\end{equation*}\normalsize

Therefore,
\small\begin{equation*}
	\lim\limits_{k\rightarrow \infty}
	P(x^T=x^{T^*}|\mathbf{z}^{i}_{1:k})=1-\lim\limits_{k\rightarrow \infty}\sum\limits_{x^T\in \bar{X}^T}P^i_{pdf}(x^T|\mathbf{z}^{i}_{1:k})=1. 
\end{equation*}\normalsize
%\begin{enumerate}
%	\item When $p_j\neq p^*_j$, i.e., $x^T\notin X^T_{eq}$,
%	\begin{align*}
%%		\lim\limits_{k\rightarrow \infty}\frac{1}{k}\ln\frac{P^i_{pdf}(x^T|\mathbf{z}^i_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^i_{1:k})} & <0,
%		\sum\limits_{j=1}^{N}p^*_j\ln \frac{p_j}{p^*_j}+(1-p^*_j)\ln \frac{1-p_j}{1-p^*_j} & <0,
%		\;\text{thus }\\
%		\lim\limits_{k\rightarrow \infty}\frac{P^i_{pdf}(x^T|\mathbf{z}^i_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^i_{1:k})} & =0
%	\end{align*}	
%	\item When $p_j= p^*_j$, i.e., $x^T\in X^T_{eq}$, \begin{align*}
%%	\lim\limits_{k\rightarrow \infty}\frac{1}{k}\ln\frac{P^i_{pdf}(x^T|\mathbf{z}^i_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^i_{1:k})} & =0,
%	\sum\limits_{j=1}^{N}p^*_j\ln \frac{p_j}{p^*_j}+(1-p^*_j)\ln \frac{1-p_j}{1-p^*_j} & = 0,
%	\;\text{thus }\\
%	\lim\limits_{k\rightarrow \infty}\frac{P^i_{pdf}(x^T|\mathbf{z}^i_{1:k})}{P^i_{pdf}(x^{T^*}|\mathbf{z}^i_{1:k})} & =1
%	\end{align*}
%\end{enumerate}
\end{proof}

\subsection{Proof for moving robots}
The difficulty of consistency proof for moving robots lies in the fact that each robot makes observations at multiple positions.
Here, the main idea is to classify robot observation positions into two disjoint sets: \textit{infinite-observation spots} that contains positions where a robot makes infinite observations, and \textit{finite-observation spots} that contains positions where the robot makes finite observations.
%, as $k\rightarrow\infty$.
Before stating main theorem, the following lemma is introduced.
\begin{lem}\label{lem1}
	\normalfont
	For a set of robots moving within a collection of finite positions, each robot has at least one position where infinite observations are made as $k$ tends to infinity.
\end{lem}

\begin{proof}
Let $n^{i,k}_j$ denote the times that $i^\text{th}$ robot visits $j^\text{th}$ position up to time $k$. Then, $\sum\limits_{j} n^{i,k}_j=k$. It is straightforward to see that $\exists n^{i,k}_j,$ such that $n^{i,k}_j\rightarrow \infty,$ as $k\rightarrow \infty$.
\end{proof}
\medskip
%The main theory of consistency of LIFO-DBF for moving robots is stated as follows:
\begin{thm}\label{thm:LIFO-dbf-mov-tar}
	\normalfont
	If robots move within a collection of finite positions, the estimated target position converges to the true position of target in probability using LIFO-DBF, i.e.,
%	the probability of estimated target position belonging to $ X^T_{eq}$ converges to one, i.e.,
%	the set of estimated target position of each robot converges to $X^T_{eq}$ in probability using LIFO-DBF when the number of observations tends to infinity, i.e.,
	\small\begin{equation*}
		\lim\limits_{k\rightarrow \infty}P(x^T=x^{T^*}|\mathbf{z}^i_{1:k})=
%		\begin{cases}
%		1 & \text{if}\; i=1\\
%		0 & \text{if}\; i\neq 1
%		\end{cases},\;
		1,\;i=1,\dots,N
	\end{equation*}\normalsize
%	where $\mathbf{z}^i_{1:k}=\left[z^1_{1:k^i_1},\dots,z^N_{1:k^i_N}\right]$.
%	, $\left\lbrace k_1,\dots,k_N\right\rbrace$ are the timestamps of $i^\text{th}$ robot's latest knowledge of all robots' observations.
\end{thm}

\begin{proof}
%Let $M^i\subseteq\left\lbrace 1,\dots,k_j\right\rbrace\times X^R $ denote the set of pair $(k,x^R)$ to indicate $j^\text{th}$ robot's position at the corresponding time of observation.
Similar to \Cref{thm:LIFO-dbf-sta-tar}, the batch form of DBF at $k^\text{th}$ step is
\small\begin{equation}\label{eqn:cmp2}
\frac{P^i_{pdf}(x^T|\mathbf{z}^i_{1:k})}{P^i_{pdf}(x^{T^{*}}|\mathbf{z}^i_{1:k})}=\frac{P^i_{pdf}(x^T)\prod\limits_{j=1}^{N}\prod\limits_{l=1}^{k^i_j}P(z^j_l|x^T;x^R_l)}{P^i_{pdf}(x^{T^{*}})\prod\limits_{j=1}^{N}\prod\limits_{l=1}^{k^i_j}P(z^j_l|x^{T^{*}};x^R_l)}. 
\end{equation}\normalsize

The only difference from \Cref{eqn:cmp} is that $P(z^j_l|x^T;x^R_l)$ in \Cref{eqn:cmp2} varies as the robot moves.
%, needs to be grouped according to the robot position. 
For each robot, there exists at least one position where infinite observations are made as $k\rightarrow \infty$, according to \Cref{lem1}. 
All positions can be classified into finite-observation spots and infinite-observation spots. 
For the former, by referring to \Cref{eqn:lim} in proof of \Cref{thm:LIFO-dbf-sta-tar}, it is easy to know that their contribution to \Cref{eqn:cmp2} is zero when $k\rightarrow \infty$.
Therefore, \Cref{eqn:cmp2} can be reduced to only consider infinite-observation spots, which is similar to proof of \Cref{thm:LIFO-dbf-sta-tar}.
\end{proof}
\medskip
\begin{rem}
	\normalfont
%	When $X^T_{eq}$ only contains $x^{T^{*}}$, consistency means the estimated target position converges to true target position in probability. Additionally, 
	Consistency implies that all individual PDFs converge to the same distribution (true target PDF), thus the consensus is also guaranteed.
	It must be noted that traditional statistics dissemination-based methods only ensure consensus of individual PDFs \cite{bandyopadhyay2014distributed,julian2012distributed}. 
	To the best knowledge of authors, there is no proof of consistency on estimated target position.
%	that guarantees the agreed PDF is close to the true target PDF.
%	 of individual PDFs.
%	In fact, the statistics dissemination-based methods can ensure the convergence of the state estimate among robots. 
%	However, there's no guarantee whether the agreed estimate is close to the actual target position.
\end{rem}

\section{Simulation}\label{sec:sim}
\begin{figure}%[thpb]
	\centering
	\begin{subfigure}[b]{0.2\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_1_1}
		\caption{Step 1}\label{fig:sta_sen_sta_tar_sing_1_1}
	\end{subfigure}
	\begin{subfigure}[b]{0.2\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_1_5}
		\caption{Step 5}\label{fig:sta_sen_sta_tar_sing_1_2}
	\end{subfigure}
	\begin{subfigure}[b]{0.2\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_1_10}
		\caption{Step 30}\label{fig:sta_sen_sta_tar_sing_1_3}
	\end{subfigure}
	\begin{subfigure}[b]{0.2\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_1_30}
		\caption{Step 30}\label{fig:sta_sen_sta_tar_single_1_4}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_3_1}
		\caption{Step 1}\label{fig:sta_sen_sta_tar_sing_3_1}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_3_5}
		\caption{Step 5}\label{fig:sta_sen_sta_tar_sing_3_2}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_3_10}
		\caption{Step 10}\label{fig:sta_sen_sta_tar_sing_3_3}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_3_30}
		\caption{Step 30}\label{fig:sta_sen_sta_tar_sing_3_4}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_5_1}
		\caption{Step 1}\label{fig:sta_sen_sta_tar_sing_5_1}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_5_5}
		\caption{Step 5}\label{fig:sta_sen_sta_tar_sing_5_2}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_5_10}
		\caption{Step 10}\label{fig:sta_sen_sta_tar_sing_5_3}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_single_5_30}
		\caption{Step 30}\label{fig:sta_sen_sta_tar_sing_5_4}
	\end{subfigure}
	\caption{Individual PDFs at different steps in ``static robots + static target'' scenario: $1^\text{st}$ robot (a)-(d); $3\text{rd}$ robot (e)-(h); $5^\text{th}$ robot (i)-(l). Robots are numbered counterclockwise, with the left-most one being the $1^\text{st}$. The square denotes this robot and stars represent other robots. The cross stands for the target.}
	\label{fig:sta_sen_sta_tar}
\end{figure}

\begin{figure}%[thpb]
	\centering
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_2_1}
		\caption{Step 1}\label{fig:mov_sen_mov_tar_sing_2_1}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_2_5}
		\caption{Step 5}\label{fig:mov_sen_mov_tar_sing_2_2}
	\end{subfigure}	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_2_10}
		\caption{Step 10}\label{fig:mov_sen_mov_tar_sing_2_3}
	\end{subfigure}	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_2_30}
		\caption{Step 30}\label{fig:mov_sen_mov_tar_sing_2_4}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_4_1}
		\caption{Step 1}\label{fig:mov_sen_mov_tar_sing_4_1}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_4_5}
		\caption{Step 5}\label{fig:mov_sen_mov_tar_sing_4_2}
	\end{subfigure}	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_4_10}
		\caption{Step 10}\label{fig:mov_sen_mov_tar_sing_4_3}
	\end{subfigure}	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_4_30}
		\caption{Step 30}\label{fig:mov_sen_mov_tar_sing_4_4}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_6_1}
		\caption{Step 1}\label{fig:mov_sen_mov_tar_sing_6_1}
	\end{subfigure}
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_6_5}
		\caption{Step 5}\label{fig:mov_sen_mov_tar_sing_6_2}
	\end{subfigure}	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_6_10}
		\caption{Step 10}\label{fig:mov_sen_mov_tar_sing_6_3}
	\end{subfigure}	
	\begin{subfigure}[b]{0.19\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_single_6_30}
		\caption{Step 30}\label{fig:mov_sen_mov_tar_sing_6_4}
	\end{subfigure}
	
	\caption{Individual PDFs at different steps in ``moving robots + moving target'' scenario: $2^\text{nd}$ robot (a)-(d); $4\text{th}$ robot (e)-(h); $6^\text{th}$ robot (i)-(l). Robots moves in circles shown in red (this robot) and green (other robots). The square and stars denote the current positions of robots. The trajectory of the target is represented by black line.}
	\label{fig:mov_sen_mov_tar}
\end{figure}

This section simulates two scenarios of target localization to demonstrate the effectiveness of LIFO-BDF. 
In all scenarios, six robots are utilized and each robot is equipped with a binary sensor. 
All sensors are modeled with identical Gaussian functions \cite{bonnie2012modelling}:
%\small\begin{align}\label{eqn:gauss_sensor}
\small\begin{subequations}\label{eqn:gauss_sensor}
	\begin{align}
		P(z^i_k=1|x_k^T;x_k^{R,i})&=e^{-\frac{1}{2}(x_k^T-x_k^{R,i})^T{\Sigma}^{-1}(x_k^T-x_k^{R,i})}\\
%		\exp\left\lbrace -\frac{1}{2}(x^T-x^R)^T{\Sigma}^{-1}(x^T-x^R)\right\rbrace \\
		P(z^i_k=0|x_k^T;x_k^{R,i})&=1-P(z^i_k=1|x_k^T;x_k^{R,i}).
	\end{align}
\end{subequations}\normalsize
%\end{align}\normalsize
%where $x^s$ denotes the robot position where current observation is obtained. 
%Figure 4 shows the 1-D illustration of Gaussian binary sensor model.
%where $x^R$ denotes the robot position, which is included in robot state $y^R$.

The first scenario consists of six static robots and a single static target.
%, which acts as a proof of concept of LIFO-DBF for static target.
The second scenario subsequently deals with six moving robots for localizing a moving target. 
Both robot and target positions are assumed to be manually controllable at each time step. 
%The third scenario contains six moving sensors and one moving target. 

\subsection{Static Robots, Static Target}\label{subsec:sim1}

The positions of six static robots are shown as stars and square in \cref{fig:sta_sen_sta_tar}.
%Each robot constantly receives binary observations of the target.
The LIFO-DBF for static target is implemented on each robot for target localization.
The networked robots use a ring communication topology that each robot can communicate with two fixed neighbors.
\cref{fig:sta_sen_sta_tar} shows the estimation results of the static target. 
After the initial observation, each robot forms a circular individual PDF, centered at its own position.
%\cref{fig:sta_sen_sta_tar_sing1} shows the individual PDF after initial observation for $1^\text{st}$ robot.
The circular PDF happens because the Gaussian sensor model (\Cref{eqn:gauss_sensor}) only depends on the distance between robot and target, not the bearing angle.
As more observations are fused, the posterior individual PDF concentrates to the true location of the target, which accords with the consistency of LIFO-DBF.
\cref{fig:sta_sen_sta_tar_entropy} shows the decreasing entropy of target PDF over time.
This confirms the effectiveness of LIFO-DBF in reducing the uncertainty of target position.
%In fact, with the Guassian sensor model (\Cref{eqn:gauss_sensor}), all positions with equal distance to a robot belong to the same equi-parameter set of the robot.
%Considering the system of six robots located separately, the equi-parameter set that contains the actual target position only contains one element.
%\cref{fig:entropy} (a) shows the decrease of the entropy of each robot's individual PDF, indicating the reduction of the uncertainty in PDF estimation.

%\subsection{Moving Robots, Static Target}
%The six robots move within the field to estimate the target position. 
%The motion planning of robots for effective target search has received much attention in the past years. 
%In this work, the robot positions are randomly generated at each time in order to demonstrate the effectiveness of LIFO-DBF approach. 
%Readers interested in robot motion planning can refer to \cite{tisdale2009autonomous,furukawa2006recursive}.
%
%\cref{fig:mov_sen_sta_tar} shows the estimation results over time. 
%Similar to the results in \cref{subsec:sim1}, the posterior individual PDF concentrates to the true target location. 
%\cref{fig:entropy} (b) shows the decrease of the entropy of the individual PDFs.
%
%\begin{figure}%[thpb]
%	\centering
%	\begin{subfigure}[b]{0.23\textwidth}
%		\includegraphics[width=\textwidth]{figures/mov_sen_sta_tar_1}
%		\caption{Step 1}\label{fig:mov_sen_sta_tar1}
%	\end{subfigure}
%	~
%	\begin{subfigure}[b]{0.23\textwidth}
%		\includegraphics[width=\textwidth]{figures/mov_sen_sta_tar_3}
%		\caption{Step 3}\label{fig:mov_sen_sta_tar2}
%	\end{subfigure}
%	~
%	\begin{subfigure}[b]{0.23\textwidth}
%		\includegraphics[width=\textwidth]{figures/mov_sen_sta_tar_10}
%		\caption{Step 10}\label{fig:mov_sen_sta_tar3}
%	\end{subfigure}
%	~
%	\begin{subfigure}[b]{0.23\textwidth}
%		\includegraphics[width=\textwidth]{figures/mov_sen_sta_tar_30}
%		\caption{Step 30}\label{fig:mov_sen_sta_tar4}
%	\end{subfigure}
%	\caption{Moving robots' individual PDFs of the static target.}
%	\label{fig:mov_sen_sta_tar}
%\end{figure}

\subsection{Moving Robots, Moving Target}
In this scenario, the six robots are controlled to move in circular trajectories periodically while the target moves linearly. Readers interested in motion planning of robots can refer to \cite{tisdale2009autonomous}. %,furukawa2006recursive
The target dynamics is given by a single-integrator model: $x^T(k+1)=x^T(k)+v\Delta T$,
%\small\begin{equation*}
%x^T(k+1)=x^T(k)+v\Delta T
%\end{equation*}\normalsize
where $v$ is the constant velocity of the target, and $\Delta T$ is the sampling time.
The LIFO-DBF described in \cref{subsec:LIFO-dbf-mov-tar} is utilized for target localization.
\cref{fig:mov_sen_mov_tar} shows the estimation results of the moving target. 
It is interesting to notice that the posterior individual PDFs concentrate to the true target location even when the target constantly moves.
\cref{fig:sta_sen_sta_tar_entropy} shows the decreasing entropy of target PDF over time.
%This confirms the effectiveness of LIFO-DBF in reducing the uncertainty of target position.%\cref{fig:entropy} (b) shows the decrease of the entropy of the posterior distribution.

%\begin{figure}%[thpb]
%	\centering
%	\includegraphics[width=0.5\textwidth]{figures/entropy_all}
%	\caption{Entropy of individual PDFs over time: (a) static robots and static target; (b) moving robots and moving target.}
%	\label{fig:entropy}
%\end{figure}

\begin{figure}%[thpb]
	\centering
	\begin{subfigure}[b]{0.23\textwidth}
		\includegraphics[width=\textwidth]{figures/sta_sen_sta_tar_entropy}
		\caption{}\label{fig:sta_sen_sta_tar_entropy}
	\end{subfigure}	
	\begin{subfigure}[b]{0.23\textwidth}
		\includegraphics[width=\textwidth]{figures/mov_sen_mov_tar_entropy}
		\caption{}\label{fig:mov_sen_mov_tar_entropy}
	\end{subfigure}
\caption{(a) Entropy of target PDF using static robots; (b) Entropy of target PDF using moving robots.}
\end{figure}

\section{CONCLUSION}\label{sec:conclu}
This paper presents a measurement dissemination-based distributed Bayesian filtering (DBF) method for a multi-robot network by utilizing the Latest-In-and-Full-Out (LIFO) protocol for observation exchange.
% for target search and tracking.
Different from statistics dissemination approaches that transmit posterior distributions or likelihood functions, each robot under LIFO only exchanges with neighboring robots a full communication buffer consisting of latest available measurements,
%only receives the latest available measurements and then broadcasts full communication buffer to its direct neighborhood by single-hopping, 
which significantly reduces the transmission burden between each pair of robots from the order of environmental size to that of robot number.
Under the condition of fixed and undirected topology, LIFO can guarantee non-intermittent dissemination of all observations over the network within finite time via local communication among direct neighborhood.
%, with each robot non-intermittently receiving observations of all others.
It is worth noting that LIFO is a general measurement exchange protocol and applicable to various sorts of sensors.
Two types of LIFO-based DBF algorithms are proposed to estimate individual PDF for static and moving target, respectively. 
For the static target, each robot locally fuses the newly received observations while for the moving target, a record set of historical observations is stored and updated. 
%Upon obtaining the latest available observations of all robots, an iterative Bayesian filtering procedure is applied that alternates between prediction and updating steps. 
The consistency of LIFO-based DBF is proved by utilizing the law of large numbers, which ensures that estimated target position converges in probability to the true target position when the number of observations tends to infinity.
%the agreement between robots' estimated target position and the actual position.
%The effectiveness of this method is demonstrated by simulations.

%In this study, we proposed the Latest-In-and-Full-Out (LIFO) strategy for distributed Bayesian filters (LIFO-DBF) in a multi-robot network.
%% with the application of distributed search and tracking (SAT) of target.
%With fixed communication topology, LIFO guarantees the global dissemination of all robots' observations over the network only via local exchange of observations among neighbors.
%Once elements in communication buffer (CB) gets filled, each robot can receive and update its CB non-intermittently under LIFO.
%Two LIFO-DBFs are proposed for SAT of a static and a moving target, respectively. 
%For the static target, each robot locally fuses the latest knowledge of all robots' observations by only considering the updating step of the Bayesian filter. 
%For the moving target, each robot maintains a triangle matrix of historical observations and an iterative Bayesian filtering procedure is applied that alternates between prediction and updating steps upon obtaining the latest available observations of all robots. 
%The consistency of LIFO-DBF is proved by showing the asymptotic concentration of posterior individual PDF to the equi-parameter set containing the actual state, ensuring the agreement between robots' state estimate using LIFO-DBF and the actual environment state.
%Simulations demonstrate the effectiveness of LIFO-DBF for SAT of both static and moving targets.

Future work includes how to handle other types of sensors and switching topology.
Other types of sensors may have biased observations and subject to non-Bernoulli distribution, which complicates the analysis of LIFO-based Bayesian filters.
The switching topology, including package loss, can lead to unpredictable delay and intermittent transmission, which may affect the consistency and consensus of LIFO-DBF. 
%In addition, combining LIFO-DBF with robot motion planning is promising for more effective SAT of target.


\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{APPENDIX}
%
%Appendixes should appear before the acknowledgment.

\section*{ACKNOWLEDGMENT}
%This work is supported by the Embedded Humans: Provably Correct Decision Making for Networks of Humans and Unmanned Systems project, a MURI project funded by the Office of Naval Research.
The authors gratefully acknowledges the Office of Naval Research for supporting the research described in this paper. This work is also partially supported by NSF China with grant 51575293.
They would also like to thank Yuting Wei in the Department of Statistics, UC Berkeley for her sincere help and fruitful discussion on the consistency proof.

%The preferred spelling of the word acknowledgment?in America is without an e?after the g? Avoid the stilted expression, One of us (R. B. G.) thanks . . .? Instead, try R. B. G. thanks? Put sponsor acknowledgments in the unnumbered footnote on the first page.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
%\bibliographystyle{bibtex}
\bibliography{references}

\end{document}
